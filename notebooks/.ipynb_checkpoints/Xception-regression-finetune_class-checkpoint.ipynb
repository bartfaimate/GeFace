{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import sys\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chdir. it depends on the platform\n",
    "if sys.platform == 'linux':\n",
    "    # if os is linux cd to\n",
    "    project_path = \"/home/mate/develop/PycharmProjects/GeFace/\"\n",
    "    NUMBER_OF_DATA = 100000\n",
    "elif sys.platform is 'windows':\n",
    "    pass\n",
    "else:\n",
    "    pass\n",
    "\n",
    "os.chdir(project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mate/develop/PycharmProjects/GeFace\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(os.getcwd())\n",
    "    # Open CSV with all informations\n",
    "    csv_file = pd.read_csv(\"faces_colored/faces_correct.csv\",delimiter = ',', encoding = \"ISO-8859-1\", engine='python')\n",
    "    pd.set_option('display.max_columns', 100)\n",
    "except (FileNotFoundError):\n",
    "    print(\"CSV file not found\")\n",
    "    current_path = os.getcwd()\n",
    "    print(\"Current path is \" + current_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nr</th>\n",
       "      <th>age</th>\n",
       "      <th>full_path</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>01/nm0000001_rm124825600_1899-5-10_1968.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>01/nm0000001_rm3343756032_1899-5-10_1970.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>01/nm0000001_rm577153792_1899-5-10_1968.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>02/nm0000002_rm1075631616_1924-9-16_1991.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>80</td>\n",
       "      <td>02/nm0000002_rm1346607872_1924-9-16_2004.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nr  age                                     full_path  gender\n",
       "0   0   69   01/nm0000001_rm124825600_1899-5-10_1968.jpg     1.0\n",
       "1   1   71  01/nm0000001_rm3343756032_1899-5-10_1970.jpg     1.0\n",
       "2   2   69   01/nm0000001_rm577153792_1899-5-10_1968.jpg     1.0\n",
       "3   5   67  02/nm0000002_rm1075631616_1924-9-16_1991.jpg     0.0\n",
       "4   6   80  02/nm0000002_rm1346607872_1924-9-16_2004.jpg     0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = csv_file.drop(columns=[\"nr\"])\n",
    "df = csv_file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert 1.0 to m as male\n",
    "#         0.0 to f as female\n",
    "def mod(x):\n",
    "    if x == 1.0:\n",
    "        x = \"m\"\n",
    "    else:\n",
    "        x = \"f\"\n",
    "    return x\n",
    "\n",
    "df[\"gender\"] = df[\"gender\"].apply(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nr</th>\n",
       "      <th>age</th>\n",
       "      <th>full_path</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>01/nm0000001_rm124825600_1899-5-10_1968.jpg</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>01/nm0000001_rm3343756032_1899-5-10_1970.jpg</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>01/nm0000001_rm577153792_1899-5-10_1968.jpg</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>02/nm0000002_rm1075631616_1924-9-16_1991.jpg</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>80</td>\n",
       "      <td>02/nm0000002_rm1346607872_1924-9-16_2004.jpg</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nr  age                                     full_path gender\n",
       "0   0   69   01/nm0000001_rm124825600_1899-5-10_1968.jpg      m\n",
       "1   1   71  01/nm0000001_rm3343756032_1899-5-10_1970.jpg      m\n",
       "2   2   69   01/nm0000001_rm577153792_1899-5-10_1968.jpg      m\n",
       "3   5   67  02/nm0000002_rm1075631616_1924-9-16_1991.jpg      f\n",
       "4   6   80  02/nm0000002_rm1346607872_1924-9-16_2004.jpg      f"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset for testing the network\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "# proba_df = df.head()\n",
    "proba_df = df.head(100)\n",
    "# Randomize but always the same random numbers\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "# shuffle rows\n",
    "proba_df = shuffle(proba_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nr</th>\n",
       "      <th>age</th>\n",
       "      <th>full_path</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>131</td>\n",
       "      <td>40</td>\n",
       "      <td>08/nm0000008_rm3248131584_1924-4-3_1964.jpg</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>72</td>\n",
       "      <td>29</td>\n",
       "      <td>04/nm0000004_rm1520029184_1949-1-24_1978.jpg</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>106</td>\n",
       "      <td>48</td>\n",
       "      <td>08/nm0000008_rm1560581632_1924-4-3_1972.jpg</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>62</td>\n",
       "      <td>31</td>\n",
       "      <td>03/nm0000003_rm3328162560_1934-9-28_1965.jpg</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>59</td>\n",
       "      <td>31</td>\n",
       "      <td>03/nm0000003_rm3277830912_1934-9-28_1965.jpg</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     nr  age                                     full_path gender\n",
       "83  131   40   08/nm0000008_rm3248131584_1924-4-3_1964.jpg      m\n",
       "53   72   29  04/nm0000004_rm1520029184_1949-1-24_1978.jpg      m\n",
       "70  106   48   08/nm0000008_rm1560581632_1924-4-3_1972.jpg      m\n",
       "45   62   31  03/nm0000003_rm3328162560_1934-9-28_1965.jpg      f\n",
       "44   59   31  03/nm0000003_rm3277830912_1934-9-28_1965.jpg      f"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 70 | valid: 20 | test: 10\n"
     ]
    }
   ],
   "source": [
    "# calculate test train valid data numbers\n",
    "test_num = int(np.floor(0.1 * proba_df.shape[0]))\n",
    "valid_num = int(np.floor(0.2 * proba_df.shape[0]))\n",
    "train_num = int(proba_df.shape[0] - test_num - valid_num)\n",
    "print(\"train: {} | valid: {} | test: {}\".format(train_num, valid_num, test_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (70, 4) | valid: (20, 4) | test: (10, 4)\n"
     ]
    }
   ],
   "source": [
    "# split the data into train valid and test data\n",
    "train_data = proba_df.iloc[0:train_num, :]\n",
    "\n",
    "valid_data = proba_df.iloc[train_num:train_num + valid_num, :]\n",
    "\n",
    "test_data = proba_df.iloc[ train_num+valid_num:, :]\n",
    "\n",
    "print(\"train: {} | valid: {} | test: {}\".format(train_data.shape, valid_data.shape, test_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'faces_colored/08/nm0000008_rm3930489088_1924-4-3_1972.jpg'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = \"faces_colored/\"\n",
    "x_train_p = image_path + train_data['full_path'].values\n",
    "x_valid_p = image_path + valid_data['full_path'].values\n",
    "x_test_p = image_path + test_data['full_path'].values\n",
    "\n",
    "\n",
    "x_test_p.shape\n",
    "x_test_p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age: 70  |  20\n"
     ]
    }
   ],
   "source": [
    "# get the ages\n",
    "y_train_age = train_data['age'].values\n",
    "y_valid_age = valid_data['age'].values\n",
    "y_test_age = test_data['age'].values\n",
    "\n",
    "print(\"age:\" ,len(y_train_age), \" | \", len(y_valid_age))\n",
    "#y_train_age\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender: 70  |  20\n"
     ]
    }
   ],
   "source": [
    "y_train_gender = train_data['gender'].values\n",
    "y_valid_gender = valid_data['gender'].values\n",
    "y_test_gender = test_data['gender'].values\n",
    "print(\"gender:\", len(y_train_gender), \" | \", len(y_valid_gender))\n",
    "\n",
    "# convert to string\n",
    "y_train_age = y_train_age.astype(\"float32\")\n",
    "y_valid_age = y_valid_age.astype(\"float32\")\n",
    "y_test_age = y_test_age.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.DataFrame({\"x_test_path\": x_test_p, \"y_test_age\": y_test_age, \"y_test_gender\": y_test_gender})\n",
    "test_data.to_csv( project_path+\"test_data.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy train, valid, test data into a new folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nr</th>\n",
       "      <th>age</th>\n",
       "      <th>full_path</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>131</td>\n",
       "      <td>40</td>\n",
       "      <td>08/nm0000008_rm3248131584_1924-4-3_1964.jpg</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>72</td>\n",
       "      <td>29</td>\n",
       "      <td>04/nm0000004_rm1520029184_1949-1-24_1978.jpg</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>106</td>\n",
       "      <td>48</td>\n",
       "      <td>08/nm0000008_rm1560581632_1924-4-3_1972.jpg</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>62</td>\n",
       "      <td>31</td>\n",
       "      <td>03/nm0000003_rm3328162560_1934-9-28_1965.jpg</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>59</td>\n",
       "      <td>31</td>\n",
       "      <td>03/nm0000003_rm3277830912_1934-9-28_1965.jpg</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     nr  age                                     full_path gender\n",
       "83  131   40   08/nm0000008_rm3248131584_1924-4-3_1964.jpg      m\n",
       "53   72   29  04/nm0000004_rm1520029184_1949-1-24_1978.jpg      m\n",
       "70  106   48   08/nm0000008_rm1560581632_1924-4-3_1972.jpg      m\n",
       "45   62   31  03/nm0000003_rm3328162560_1934-9-28_1965.jpg      f\n",
       "44   59   31  03/nm0000003_rm3277830912_1934-9-28_1965.jpg      f"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "import sys\n",
    "import os\n",
    "import PIL\n",
    "# import the necessary packages\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import *\n",
    "from keras.applications import Xception\n",
    "from keras.models import Model, Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.utils.vis_utils import plot_model\n",
    " \n",
    "# import the necessary packages\n",
    "#from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from pyimagesearch.smallervggnet import SmallerVGGNet\n",
    "# from imutils import paths\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "agesBranch = None\n",
    "genderBranch = None\n",
    "class FaceNet:\n",
    "    \n",
    "    @staticmethod\n",
    "    def build_ages_branch(inputs, numAges, finalAct=\"sigmoid\", chanDim=-1):\n",
    "        # utilize a lambda layer to convert the 3 channel input to a\n",
    "        # grayscale representation\n",
    "        x = Conv2D(32, (3, 3), padding=\"same\")(inputs) \n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=chanDim)(x)\n",
    "        x = MaxPooling2D(pool_size=(3, 3))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "        x = Flatten()(x)\n",
    "        predictions = Dense(1, activation=finalAct,name=\"ages_output\")(x)\n",
    "        # add your top layer block to your base model\n",
    "\n",
    "        #print(model.summary())\n",
    "    \n",
    "        # define a branch of output layers for the number of different\n",
    "        # ages\n",
    "        # return the category prediction sub-network\n",
    "        return predictions\n",
    "    \n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def build_gender_branch(inputs, numGender, finalAct=\"softmax\", chanDim=-1):\n",
    "       \n",
    "        padding = \"same\"\n",
    "        # CONV => RELU => POOL\n",
    "        x = Conv2D(32, (3, 3), padding=padding, trainable=False)(inputs) \n",
    "        x = Activation(\"relu\",trainable=False)(x)\n",
    "        x = BatchNormalization(axis=chanDim,trainable=False)(x)\n",
    "        x = MaxPooling2D(pool_size=(3, 3),trainable=False)(x)\n",
    "        x = Dropout(0.25,trainable=False)(x)\n",
    "        \n",
    "        # CONV => RELU => POOL\n",
    "        x = Conv2D(32, (3, 3), padding=padding, trainable=False)(x) \n",
    "        x = Activation(\"relu\", trainable=False)(x)\n",
    "        x = BatchNormalization(axis=chanDim,trainable=False)(x)\n",
    "        x = MaxPooling2D(pool_size=(3, 3),trainable=False)(x)\n",
    "        x = Dropout(0.25,trainable=False)(x)\n",
    "        \n",
    "        # (CONV => RELU) * 2 => POOL\n",
    "        x = Conv2D(64, (5, 5), padding=padding,trainable=False)(x)\n",
    "        x = Activation(\"relu\",trainable=False)(x)\n",
    "        x = BatchNormalization(axis=chanDim,trainable=False)(x)\n",
    "        x = Conv2D(64, (3, 3), padding=padding,trainable=False)(x)\n",
    "        x = Activation(\"relu\",trainable=False)(x)\n",
    "        x = BatchNormalization(axis=chanDim,trainable=False)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2),trainable=False)(x)\n",
    "        x = Dropout(0.25,trainable=False)(x)\n",
    "        \n",
    "        \n",
    "        # (CONV => RELU) * 2 => POOL\n",
    "        x = Conv2D(64, (5, 5), padding=padding,trainable=False)(x)\n",
    "        x = Activation(\"relu\",trainable=False)(x)\n",
    "        x = BatchNormalization(axis=chanDim,trainable=False)(x)\n",
    "        x = Conv2D(64, (3, 3), padding=padding,trainable=False)(x)\n",
    "        x = Activation(\"relu\",trainable=False)(x)\n",
    "        x = BatchNormalization(axis=chanDim,trainable=False)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2),trainable=False)(x)\n",
    "        x = Dropout(0.25,trainable=False)(x)\n",
    " \n",
    "        # (CONV => RELU) * 2 => POOL\n",
    "        x = Conv2D(128, (3, 3), padding=padding,trainable=False)(x)\n",
    "        x = Activation(\"relu\",trainable=False)(x)\n",
    "        x = BatchNormalization(axis=chanDim,trainable=False)(x)\n",
    "        x = Conv2D(128, (3, 3), padding=padding,trainable=False)(x)\n",
    "        x = Activation(\"relu\",trainable=False)(x)\n",
    "        x = BatchNormalization(axis=chanDim,trainable=False)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2),trainable=False)(x)\n",
    "        x = Dropout(0.25,trainable=False)(x)\n",
    "        \n",
    "        # define a branch of output layers for the number of different\n",
    "        # genders\n",
    "        x = Flatten(trainable=False)(x)\n",
    "        x = Dense(128,trainable=False)(x)\n",
    "        x = Activation(\"relu\",trainable=False)(x)\n",
    "        x = BatchNormalization(trainable=False)(x)\n",
    "        x = Dropout(0.5,trainable=False)(x)\n",
    "        x = Dense(numGender,trainable=False)(x)\n",
    "        x = Activation(finalAct, name=\"gender_output\",trainable=False)(x)\n",
    " \n",
    "        # return the color prediction sub-network\n",
    "        return x\n",
    "    \n",
    "    @staticmethod\n",
    "    def build(width, height, numAges, numGenders, finalAct=\"softmax\"):\n",
    "        # initialize the input shape and channel dimension (this code\n",
    "        # assumes you are using TensorFlow which utilizes channels\n",
    "        # last ordering)\n",
    "        inputShape = (height, width, 3)\n",
    "        chanDim = -1\n",
    "        base_model = Xception(input_shape=inputShape, \n",
    "                              weights=None, include_top=False)\n",
    "        \n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = True\n",
    "            \n",
    "        # construct both the \"category\" and \"color\" sub-networks\n",
    "        inputs = base_model.input\n",
    "        global agesBranch\n",
    "        global genderBranch\n",
    "        agesBranch = FaceNet.build_ages_branch(base_model.output,\n",
    "            numAges, finalAct=\"sigmoid\", chanDim=chanDim)\n",
    "#         for layer in agesBranch.layers:\n",
    "#             layer.trainable = False\n",
    "        genderBranch = FaceNet.build_gender_branch(inputs,\n",
    "            numGenders, finalAct=finalAct, chanDim=chanDim)\n",
    " \n",
    "        # create the model using our input (the batch of images) and\n",
    "        # two separate outputs -- one for the clothing category\n",
    "        # branch and another for the color branch, respectively\n",
    "        model = Model(\n",
    "            inputs=inputs,\n",
    "            outputs=[agesBranch, genderBranch],\n",
    "            )\n",
    "        \n",
    "        print(model.summary())\n",
    "        plot_model(model, show_shapes=True, show_layer_names=True)\n",
    "       \n",
    "        # return the constructed network architecture\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix seed for reproducible results (only works on CPU, not GPU)\n",
    "seed = 42\n",
    "np.random.seed(seed=seed)\n",
    "tf.set_random_seed(seed=seed)\n",
    "\n",
    "# initialize the number of epochs to train for, initial learning rate,\n",
    "# batch size, and image dimensions\n",
    "EPOCHS = 100\n",
    "INIT_LR = 1e-3\n",
    "BS = 64\n",
    "IMAGE_DIMS = (96, 96, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_gender = LabelBinarizer()\n",
    "# lb_age = StandardScaler()\n",
    "lb_age = MinMaxScaler()\n",
    "\n",
    "y_train_age = y_train_age.reshape(-1, 1)\n",
    "y_valid_age = y_valid_age.reshape(-1, 1)\n",
    "\n",
    "y_train_gender = lb_gender.fit_transform(y_train_gender)\n",
    "y_train_age = lb_age.fit_transform(y_train_age)\n",
    "y_train_gender = [y_train_gender, 1-y_train_gender]\n",
    "\n",
    "y_valid_gender = lb_gender.transform(y_valid_gender)\n",
    "y_valid_age = lb_age.transform(y_valid_age)\n",
    "y_valid_gender = [y_valid_gender, 1-y_valid_gender]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_age.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mate/develop/PycharmProjects/GeFace/faces_colored/08/nm0000008_rm2733021440_1924-4-3_1966.jpg'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_path+x_valid_p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
    "\theight_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "\thorizontal_flip=True, fill_mode=\"nearest\",\n",
    "#     brightness_range=(0.2,1.0),\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainImageLoader(files_x, y_train_age, y_train_gender, batch_size,L):\n",
    "\n",
    "    #this line is just to make the generator infinite, keras needs that    \n",
    "    while True:\n",
    "\n",
    "        batch_start = 0\n",
    "        batch_end = batch_size\n",
    "\n",
    "        while batch_start < L:\n",
    "            limit = min(batch_end, L)\n",
    "            train_x = []\n",
    "            for file in files_x[batch_start:limit]:\n",
    "                image = cv2.imread(project_path+file)\n",
    "                image = img_to_array(image)\n",
    "                train_x.append(image)\n",
    "            train_x = np.array(train_x, dtype=\"float32\") * 2.0 / 255.0 - 1\n",
    "            train_y = y_train_age\n",
    "            \n",
    "            y_train_g = np.array(y_train_gender).squeeze().T[batch_start:limit]\n",
    "            \n",
    "            y_train_a = np.array(train_y)[batch_start:limit]\n",
    "        \n",
    "\n",
    "            yield (train_x,{\"ages_output\": y_train_a, \"gender_output\": y_train_g}) #a tuple with two numpy arrays with batch_size samples     \n",
    "\n",
    "            batch_start += batch_size   \n",
    "            batch_end += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validImageLoader(files_x, y_valid_age, y_valid_gender, batch_size,L):\n",
    "\n",
    "    #this line is just to make the generator infinite, keras needs that    \n",
    "    while True:\n",
    "\n",
    "        batch_start = 0\n",
    "        batch_end = batch_size\n",
    "\n",
    "        while batch_start < L:\n",
    "            limit = min(batch_end, L)\n",
    "            valid_x = []\n",
    "            for file in files_x[batch_start:limit]:\n",
    "                image = cv2.imread(project_path+file)\n",
    "                image = img_to_array(image)\n",
    "                valid_x.append(image)\n",
    "            valid_x = np.array(valid_x, dtype=\"float32\") * 2.0 / 255.0 - 1\n",
    "            valid_y = y_valid_age\n",
    "            \n",
    "            y_valid_g = np.array(y_valid_gender).squeeze().T[batch_start:limit]\n",
    "            y_valid_a = np.array(valid_y)[batch_start:limit]\n",
    "        \n",
    "\n",
    "            yield (valid_x,{\"ages_output\": y_valid_a, \"gender_output\": y_valid_g}) #a tuple with two numpy arrays with batch_size samples     \n",
    "\n",
    "            batch_start += batch_size   \n",
    "            batch_end += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 96, 96, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 47, 47, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 47, 47, 32)   128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 47, 47, 32)   0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 45, 45, 64)   18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 45, 45, 64)   256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 45, 45, 64)   0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 45, 45, 128)  8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 45, 45, 128)  512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 45, 45, 128)  0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 45, 45, 128)  17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 45, 45, 128)  512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 23, 23, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 23, 23, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 23, 23, 128)  512         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 23, 23, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 23, 23, 128)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 23, 23, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 23, 23, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 23, 23, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 23, 23, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 23, 23, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 12, 12, 256)  32768       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 12, 12, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 12, 12, 256)  1024        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 12, 12, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 12, 12, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 12, 12, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 12, 12, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 12, 12, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 12, 12, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 12, 12, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 6, 6, 728)    186368      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 6, 6, 728)    0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 6, 6, 728)    2912        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 6, 6, 728)    0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 6, 6, 728)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 6, 6, 728)    0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 6, 6, 728)    0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 6, 6, 728)    0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 6, 6, 728)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 6, 6, 728)    0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 6, 6, 728)    0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 6, 6, 728)    0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 6, 6, 728)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 6, 6, 728)    0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 6, 6, 728)    0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 6, 6, 728)    0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 6, 6, 728)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 6, 6, 728)    0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 6, 6, 728)    0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 6, 6, 728)    0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 6, 6, 728)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 6, 6, 728)    0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 6, 6, 728)    0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 6, 6, 728)    0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 6, 6, 728)    0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 6, 6, 728)    536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 6, 6, 728)    2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 6, 6, 728)    0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 6, 6, 728)    536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 6, 6, 728)    2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 6, 6, 728)    0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 96, 96, 32)   896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 96, 96, 32)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 96, 96, 32)   128         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 6, 6, 728)    0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 32)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 6, 6, 728)    536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32, 32, 32)   0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 6, 6, 728)    2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 32)   9248        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 6, 6, 728)    0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 32)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 6, 6, 728)    536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 32)   128         activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 6, 6, 728)    2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 10, 10, 32)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 6, 6, 728)    0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 10, 10, 32)   0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 10, 10, 64)   51264       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 10, 10, 64)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 10, 10, 64)   256         activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 6, 6, 728)    0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 10, 10, 64)   36928       batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 6, 6, 728)    536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 10, 10, 64)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 6, 6, 728)    2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 10, 10, 64)   256         activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 6, 6, 728)    0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 5, 5, 64)     0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 6, 6, 728)    536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 5, 5, 64)     0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 6, 6, 728)    2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 5, 5, 64)     102464      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 6, 6, 728)    0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 5, 5, 64)     0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 5, 5, 64)     256         activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 5, 5, 64)     36928       batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 5, 5, 64)     0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 6, 6, 728)    0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 5, 5, 64)     256         activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 6, 6, 1024)   752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 2, 2, 64)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 6, 6, 1024)   4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 3, 3, 1024)   745472      add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 2, 2, 64)     0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 3, 3, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 3, 3, 1024)   4096        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 2, 2, 128)    73856       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 3, 3, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 2, 2, 128)    0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 3, 3, 1536)   1582080     add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 2, 2, 128)    512         activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 3, 3, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 2, 2, 128)    147584      batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 3, 3, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 2, 2, 128)    0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 3, 3, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 2, 2, 128)    512         activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 3, 3, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 1, 1, 128)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 3, 3, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1, 1, 128)    0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 3, 3, 32)     589856      block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 128)          0           dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 3, 3, 32)     0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          16512       flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 3, 3, 32)     128         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 32)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 128)          512         activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1, 1, 32)     0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 128)          0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 32)           0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            258         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ages_output (Dense)             (None, 1)            33          flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gender_output (Activation)      (None, 2)            0           dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 21,930,251\n",
      "Trainable params: 21,396,905\n",
      "Non-trainable params: 533,346\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 1.4472 - ages_output_loss: 0.3060 - gender_output_loss: 1.1412 - ages_output_acc: 0.0000e+00 - gender_output_acc: 0.5469 - val_loss: 1.1603 - val_ages_output_loss: 0.4668 - val_gender_output_loss: 0.6935 - val_ages_output_acc: 0.0000e+00 - val_gender_output_acc: 0.5000\n",
      "\n",
      "Epoch 00001: val_ages_output_loss improved from inf to 0.46675, saving model to /home/mate/develop/PycharmProjects/GeFace/gen_ages_model.hdf5\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 4s 440ms/step - loss: 1.5615 - ages_output_loss: 0.2040 - gender_output_loss: 1.3575 - ages_output_acc: 0.0000e+00 - gender_output_acc: 0.4483 - val_loss: 1.1536 - val_ages_output_loss: 0.4599 - val_gender_output_loss: 0.6937 - val_ages_output_acc: 0.0000e+00 - val_gender_output_acc: 0.5000\n",
      "\n",
      "Epoch 00002: val_ages_output_loss improved from 0.46675 to 0.45987, saving model to /home/mate/develop/PycharmProjects/GeFace/gen_ages_model.hdf5\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 2s 295ms/step - loss: 1.4349 - ages_output_loss: 0.1636 - gender_output_loss: 1.2713 - ages_output_acc: 0.0203 - gender_output_acc: 0.5157 - val_loss: 0.9141 - val_ages_output_loss: 0.2215 - val_gender_output_loss: 0.6926 - val_ages_output_acc: 0.0000e+00 - val_gender_output_acc: 0.6667\n",
      "\n",
      "Epoch 00003: val_ages_output_loss improved from 0.45987 to 0.22149, saving model to /home/mate/develop/PycharmProjects/GeFace/gen_ages_model.hdf5\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 3s 356ms/step - loss: 1.3289 - ages_output_loss: 0.1935 - gender_output_loss: 1.1353 - ages_output_acc: 0.0000e+00 - gender_output_acc: 0.5517 - val_loss: 1.0294 - val_ages_output_loss: 0.3358 - val_gender_output_loss: 0.6935 - val_ages_output_acc: 0.0000e+00 - val_gender_output_acc: 0.5000\n",
      "\n",
      "Epoch 00004: val_ages_output_loss did not improve from 0.22149\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 3s 336ms/step - loss: 1.5626 - ages_output_loss: 0.0793 - gender_output_loss: 1.4834 - ages_output_acc: 0.0203 - gender_output_acc: 0.4733 - val_loss: 1.1514 - val_ages_output_loss: 0.4577 - val_gender_output_loss: 0.6937 - val_ages_output_acc: 0.0000e+00 - val_gender_output_acc: 0.5000\n",
      "\n",
      "Epoch 00005: val_ages_output_loss did not improve from 0.22149\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 3s 322ms/step - loss: 1.0509 - ages_output_loss: 0.1143 - gender_output_loss: 0.9366 - ages_output_acc: 0.0000e+00 - gender_output_acc: 0.6144 - val_loss: 0.8699 - val_ages_output_loss: 0.1772 - val_gender_output_loss: 0.6926 - val_ages_output_acc: 0.0833 - val_gender_output_acc: 0.6667\n",
      "\n",
      "Epoch 00006: val_ages_output_loss improved from 0.22149 to 0.17724, saving model to /home/mate/develop/PycharmProjects/GeFace/gen_ages_model.hdf5\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 3s 362ms/step - loss: 1.3708 - ages_output_loss: 0.0827 - gender_output_loss: 1.2880 - ages_output_acc: 0.0203 - gender_output_acc: 0.4326 - val_loss: 1.0168 - val_ages_output_loss: 0.3233 - val_gender_output_loss: 0.6935 - val_ages_output_acc: 0.0625 - val_gender_output_acc: 0.5000\n",
      "\n",
      "Epoch 00007: val_ages_output_loss did not improve from 0.17724\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 3s 357ms/step - loss: 1.4801 - ages_output_loss: 0.0781 - gender_output_loss: 1.4020 - ages_output_acc: 0.0203 - gender_output_acc: 0.4483 - val_loss: 1.0548 - val_ages_output_loss: 0.3611 - val_gender_output_loss: 0.6937 - val_ages_output_acc: 0.0000e+00 - val_gender_output_acc: 0.5000\n",
      "\n",
      "Epoch 00008: val_ages_output_loss did not improve from 0.17724\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 2s 312ms/step - loss: 1.2171 - ages_output_loss: 0.0528 - gender_output_loss: 1.1643 - ages_output_acc: 0.0203 - gender_output_acc: 0.5360 - val_loss: 0.7764 - val_ages_output_loss: 0.0838 - val_gender_output_loss: 0.6926 - val_ages_output_acc: 0.0833 - val_gender_output_acc: 0.6667\n",
      "\n",
      "Epoch 00009: val_ages_output_loss improved from 0.17724 to 0.08381, saving model to /home/mate/develop/PycharmProjects/GeFace/gen_ages_model.hdf5\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 2s 306ms/step - loss: 1.2606 - ages_output_loss: 0.0430 - gender_output_loss: 1.2175 - ages_output_acc: 0.0000e+00 - gender_output_acc: 0.5312 - val_loss: 0.9263 - val_ages_output_loss: 0.2328 - val_gender_output_loss: 0.6935 - val_ages_output_acc: 0.0625 - val_gender_output_acc: 0.5000\n",
      "\n",
      "Epoch 00010: val_ages_output_loss did not improve from 0.08381\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 2s 310ms/step - loss: 1.0660 - ages_output_loss: 0.0631 - gender_output_loss: 1.0028 - ages_output_acc: 0.0203 - gender_output_acc: 0.4889 - val_loss: 0.9503 - val_ages_output_loss: 0.2566 - val_gender_output_loss: 0.6937 - val_ages_output_acc: 0.0000e+00 - val_gender_output_acc: 0.5000\n",
      "\n",
      "Epoch 00011: val_ages_output_loss did not improve from 0.08381\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 2s 308ms/step - loss: 1.2900 - ages_output_loss: 0.0557 - gender_output_loss: 1.2343 - ages_output_acc: 0.0203 - gender_output_acc: 0.3902 - val_loss: 0.7637 - val_ages_output_loss: 0.0711 - val_gender_output_loss: 0.6926 - val_ages_output_acc: 0.0833 - val_gender_output_acc: 0.6667\n",
      "\n",
      "Epoch 00012: val_ages_output_loss improved from 0.08381 to 0.07105, saving model to /home/mate/develop/PycharmProjects/GeFace/gen_ages_model.hdf5\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 2s 305ms/step - loss: 1.1366 - ages_output_loss: 0.0536 - gender_output_loss: 1.0830 - ages_output_acc: 0.0203 - gender_output_acc: 0.6301 - val_loss: 0.8999 - val_ages_output_loss: 0.2064 - val_gender_output_loss: 0.6935 - val_ages_output_acc: 0.0625 - val_gender_output_acc: 0.5000\n",
      "\n",
      "Epoch 00013: val_ages_output_loss did not improve from 0.07105\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 2s 303ms/step - loss: 1.2054 - ages_output_loss: 0.0520 - gender_output_loss: 1.1534 - ages_output_acc: 0.0203 - gender_output_acc: 0.5877 - val_loss: 0.8865 - val_ages_output_loss: 0.1928 - val_gender_output_loss: 0.6937 - val_ages_output_acc: 0.0000e+00 - val_gender_output_acc: 0.5000\n",
      "\n",
      "Epoch 00014: val_ages_output_loss did not improve from 0.07105\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 2s 303ms/step - loss: 1.0504 - ages_output_loss: 0.0469 - gender_output_loss: 1.0035 - ages_output_acc: 0.0203 - gender_output_acc: 0.5627 - val_loss: 0.7746 - val_ages_output_loss: 0.0819 - val_gender_output_loss: 0.6926 - val_ages_output_acc: 0.0833 - val_gender_output_acc: 0.6667\n",
      "\n",
      "Epoch 00015: val_ages_output_loss did not improve from 0.07105\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 3s 365ms/step - loss: 1.3485 - ages_output_loss: 0.0480 - gender_output_loss: 1.3005 - ages_output_acc: 0.0203 - gender_output_acc: 0.3967 - val_loss: 0.9150 - val_ages_output_loss: 0.2215 - val_gender_output_loss: 0.6935 - val_ages_output_acc: 0.0625 - val_gender_output_acc: 0.5000\n",
      "\n",
      "Epoch 00016: val_ages_output_loss did not improve from 0.07105\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 2s 298ms/step - loss: 1.3008 - ages_output_loss: 0.0477 - gender_output_loss: 1.2530 - ages_output_acc: 0.0203 - gender_output_acc: 0.4326 - val_loss: 0.9736 - val_ages_output_loss: 0.2799 - val_gender_output_loss: 0.6937 - val_ages_output_acc: 0.0000e+00 - val_gender_output_acc: 0.5000\n",
      "\n",
      "Epoch 00017: val_ages_output_loss did not improve from 0.07105\n",
      "Epoch 00017: early stopping\n",
      "[INFO] serializing network...\n",
      "[INFO] serializing category label binarizer...\n"
     ]
    }
   ],
   "source": [
    "# initialize the model\n",
    "print(\"[INFO] compiling model...\")\n",
    "# load model\n",
    "model = FaceNet.build(IMAGE_DIMS[0], IMAGE_DIMS[1], numAges=1, \n",
    "                      numGenders=2,finalAct=\"softmax\" )\n",
    "# create optimazitions method\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "\n",
    "#model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "# metrics=[\"accuracy\"])\n",
    "losses = {\"ages_output\": \"mse\", \"gender_output\": \"categorical_crossentropy\",}\n",
    "lossWeights = {\"ages_output\": 1.0, \"gender_output\": 1.0}\n",
    "\n",
    "model.compile(loss=losses, optimizer=opt,metrics=[\"accuracy\"])\n",
    "\n",
    "# Create callback list for checkpoint and Earlystopping\n",
    "callbacks_list = [\n",
    "    ModelCheckpoint(project_path+\"gen_ages_model.hdf5\", monitor='val_ages_output_loss', verbose=1, save_best_only=True),\n",
    "    EarlyStopping(monitor='val_ages_output_loss', patience=5, verbose=1)\n",
    "    ]\n",
    "\n",
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "TBS = 8\n",
    "\n",
    "\n",
    "\n",
    "History = model.fit_generator(\n",
    "    trainImageLoader(x_train_p,y_train_age, y_train_gender,TBS,len(x_train_p)),\n",
    "    steps_per_epoch=len(x_train_p) // TBS,\n",
    "    validation_data=validImageLoader(x_valid_p,y_valid_age,y_valid_gender,TBS,len(x_valid_p)),\n",
    "    validation_steps = len(x_valid_p) // TBS,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks_list,\n",
    ")\n",
    "\n",
    "# save the model to disk\n",
    "print(\"[INFO] serializing network...\")\n",
    " \n",
    "# save the category binarizer to disk\n",
    "print(\"[INFO] serializing category label binarizer...\")\n",
    "f = open(project_path+\"regression.label\", \"wb\")\n",
    "f.write(pickle.dumps(lb_age))\n",
    "f.close()\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "REAL_EPOCH = len(History.epoch)\n",
    "# print(y_train_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(History.epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_names = [\"val_loss\", \"val_ages_output_loss\", \"val_gender_output_loss\",\n",
    "              \"ages_output_acc\", \"gender_output_acc\",\n",
    "             \"val_gender_output_acc\", \"val_ages_output_acc\"]\n",
    "\n",
    "epoch_save = np.arange(0, REAL_EPOCH)\n",
    "val_loss_save = History.history[loss_names[0]]\n",
    "val_ages_out_save = History.history[loss_names[1]]\n",
    "val_gender_out_save = History.history[loss_names[2]]\n",
    "\n",
    "loss_file = open(project_path + \"loss_save.csv\", \"w\")\n",
    "\n",
    "head = \"epoch_num\"\n",
    "\n",
    "for lo in loss_names:\n",
    "    head += \",\" +lo\n",
    "head +=\"\\n\"\n",
    "loss_file.write(head)\n",
    "\n",
    "for i in range(REAL_EPOCH):\n",
    "    line = \"\"\n",
    "    line += str(i)\n",
    "    for lo in loss_names:\n",
    "        line += \",{}\".format(History.history[lo][i])\n",
    "        \n",
    "    line +=\"\\n\"\n",
    "    loss_file.write(line)\n",
    "    \n",
    "#     loss_file.write(\"{},{},{},{}\\n\".format(i, val_loss_save[i], val_ages_out_save[i], val_gender_out_save[i]))\n",
    "\n",
    "loss_file.close()\n",
    "\n",
    "# plt.style.use(\"ggplot\")\n",
    "\n",
    "# (fig, ax) = plt.subplots(2, 1, figsize=(8,8))\n",
    "\n",
    "# for (i, l) in enumerate(loss_names):\n",
    "#     ax[i].set_title(\"Loss for {}\".format(l))\n",
    "#     ax[i].set_xlabel(\"Epochs\")\n",
    "#     ax[i].set_ylabel(\"Loss\")\n",
    "#     ax[i].plot(np.arange(0, REAL_EPOCH), History.history[l], label=l)\n",
    "#     ax[i].plot(np.arange(0, REAL_EPOCH), History.history[l],label=l)\n",
    "#     ax[i].legend()\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(\"multi_loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(1)])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agesBranch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mate/.virtualenvs/deeplearn_gpu/lib/python3.6/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 2s 305ms/step - loss: 1.3246 - ages_output_loss: 0.0278 - gender_output_loss: 1.2968 - ages_output_acc: 0.0000e+00 - gender_output_acc: 0.5625 - val_loss: 0.9223 - val_ages_output_loss: 0.2288 - val_gender_output_loss: 0.6935 - val_ages_output_acc: 0.0625 - val_gender_output_acc: 0.5000\n",
      "\n",
      "Epoch 00001: val_gender_output_acc improved from -inf to 0.50000, saving model to /home/mate/develop/PycharmProjects/GeFace/fine_gender_model.hdf5\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 2s 294ms/step - loss: 1.0957 - ages_output_loss: 0.0439 - gender_output_loss: 1.0517 - ages_output_acc: 0.0203 - gender_output_acc: 0.5453 - val_loss: 0.9722 - val_ages_output_loss: 0.2785 - val_gender_output_loss: 0.6937 - val_ages_output_acc: 0.0000e+00 - val_gender_output_acc: 0.5000\n",
      "\n",
      "Epoch 00002: val_gender_output_acc did not improve from 0.50000\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 2s 298ms/step - loss: 1.4678 - ages_output_loss: 0.0457 - gender_output_loss: 1.4220 - ages_output_acc: 0.0203 - gender_output_acc: 0.5221 - val_loss: 0.7946 - val_ages_output_loss: 0.1020 - val_gender_output_loss: 0.6926 - val_ages_output_acc: 0.0833 - val_gender_output_acc: 0.6667\n",
      "\n",
      "Epoch 00003: val_gender_output_acc improved from 0.50000 to 0.66667, saving model to /home/mate/develop/PycharmProjects/GeFace/fine_gender_model.hdf5\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 2s 296ms/step - loss: 1.2171 - ages_output_loss: 0.0432 - gender_output_loss: 1.1739 - ages_output_acc: 0.0203 - gender_output_acc: 0.5923 - val_loss: 0.8823 - val_ages_output_loss: 0.1888 - val_gender_output_loss: 0.6935 - val_ages_output_acc: 0.0625 - val_gender_output_acc: 0.5000\n",
      "\n",
      "Epoch 00004: val_gender_output_acc did not improve from 0.66667\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 2s 301ms/step - loss: 1.1765 - ages_output_loss: 0.0437 - gender_output_loss: 1.1328 - ages_output_acc: 0.0203 - gender_output_acc: 0.4419 - val_loss: 0.8366 - val_ages_output_loss: 0.1429 - val_gender_output_loss: 0.6937 - val_ages_output_acc: 0.0000e+00 - val_gender_output_acc: 0.5000\n",
      "\n",
      "Epoch 00005: val_gender_output_acc did not improve from 0.66667\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 2s 298ms/step - loss: 1.3972 - ages_output_loss: 0.0316 - gender_output_loss: 1.3656 - ages_output_acc: 0.0203 - gender_output_acc: 0.5221 - val_loss: 0.8344 - val_ages_output_loss: 0.1418 - val_gender_output_loss: 0.6926 - val_ages_output_acc: 0.0833 - val_gender_output_acc: 0.6667\n",
      "\n",
      "Epoch 00006: val_gender_output_acc did not improve from 0.66667\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 3s 350ms/step - loss: 1.6020 - ages_output_loss: 0.0436 - gender_output_loss: 1.5584 - ages_output_acc: 0.0203 - gender_output_acc: 0.3967 - val_loss: 0.8359 - val_ages_output_loss: 0.1423 - val_gender_output_loss: 0.6935 - val_ages_output_acc: 0.0625 - val_gender_output_acc: 0.5000\n",
      "\n",
      "Epoch 00007: val_gender_output_acc did not improve from 0.66667\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 2s 307ms/step - loss: 1.3898 - ages_output_loss: 0.0369 - gender_output_loss: 1.3529 - ages_output_acc: 0.0203 - gender_output_acc: 0.4216 - val_loss: 0.8918 - val_ages_output_loss: 0.1982 - val_gender_output_loss: 0.6937 - val_ages_output_acc: 0.0000e+00 - val_gender_output_acc: 0.5000\n",
      "\n",
      "Epoch 00008: val_gender_output_acc did not improve from 0.66667\n",
      "Epoch 00008: early stopping\n",
      "[INFO] serializing category label binarizer...\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = not layer.trainable\n",
    "\n",
    "callbacks_list = [\n",
    "    ModelCheckpoint(project_path+\"fine_gender_model.hdf5\", monitor='val_gender_output_acc', verbose=1, save_best_only=True),\n",
    "    EarlyStopping(monitor='val_gender_output_acc', patience=5, verbose=1)\n",
    "    ]\n",
    "\n",
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "TBS = 8\n",
    "\n",
    "model.compile(loss=losses, optimizer=opt,metrics=[\"accuracy\"])\n",
    "\n",
    "model.load_weights(project_path+\"gen_ages_model.hdf5\")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "History = model.fit_generator(\n",
    "    trainImageLoader(x_train_p,y_train_age, y_train_gender,TBS,len(x_train_p)),\n",
    "    steps_per_epoch=len(x_train_p) // TBS,\n",
    "    validation_data=validImageLoader(x_valid_p,y_valid_age,y_valid_gender,TBS,len(x_valid_p)),\n",
    "    validation_steps = len(x_valid_p) // TBS,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks_list,\n",
    ")\n",
    "\n",
    " \n",
    "# save the category binarizer to disk\n",
    "print(\"[INFO] serializing category label binarizer...\")\n",
    "f = open(project_path+\"fine_regression.label\", \"wb\")\n",
    "f.write(pickle.dumps(lb_age))\n",
    "f.close()\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 96, 96, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 47, 47, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 47, 47, 32)   128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 47, 47, 32)   0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 45, 45, 64)   18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 45, 45, 64)   256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 45, 45, 64)   0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 45, 45, 128)  8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 45, 45, 128)  512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 45, 45, 128)  0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 45, 45, 128)  17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 45, 45, 128)  512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 23, 23, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 23, 23, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 23, 23, 128)  512         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 23, 23, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 23, 23, 128)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 23, 23, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 23, 23, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 23, 23, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 23, 23, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 23, 23, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 12, 12, 256)  32768       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 12, 12, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 12, 12, 256)  1024        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 12, 12, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 12, 12, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 12, 12, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 12, 12, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 12, 12, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 12, 12, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 12, 12, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 6, 6, 728)    186368      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 6, 6, 728)    0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 6, 6, 728)    2912        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 6, 6, 728)    0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 6, 6, 728)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 6, 6, 728)    0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 6, 6, 728)    0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 6, 6, 728)    0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 6, 6, 728)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 6, 6, 728)    0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 6, 6, 728)    0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 6, 6, 728)    0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 6, 6, 728)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 6, 6, 728)    0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 6, 6, 728)    0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 6, 6, 728)    0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 6, 6, 728)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 6, 6, 728)    0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 6, 6, 728)    0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 6, 6, 728)    0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 6, 6, 728)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 6, 6, 728)    0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 6, 6, 728)    0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 6, 6, 728)    0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 6, 6, 728)    0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 6, 6, 728)    536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 6, 6, 728)    2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 6, 6, 728)    0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 6, 6, 728)    536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 6, 6, 728)    2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 6, 6, 728)    0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 96, 96, 32)   896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 96, 96, 32)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 96, 96, 32)   128         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 6, 6, 728)    0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 32)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 6, 6, 728)    536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32, 32, 32)   0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 6, 6, 728)    2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 32)   9248        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 6, 6, 728)    0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 32)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 6, 6, 728)    536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 32)   128         activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 6, 6, 728)    2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 10, 10, 32)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 6, 6, 728)    0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 10, 10, 32)   0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 10, 10, 64)   51264       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 10, 10, 64)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 10, 10, 64)   256         activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 6, 6, 728)    0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 10, 10, 64)   36928       batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 6, 6, 728)    536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 10, 10, 64)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 6, 6, 728)    2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 10, 10, 64)   256         activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 6, 6, 728)    0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 5, 5, 64)     0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 6, 6, 728)    536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 5, 5, 64)     0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 6, 6, 728)    2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 5, 5, 64)     102464      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 6, 6, 728)    0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 5, 5, 64)     0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 5, 5, 64)     256         activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 5, 5, 64)     36928       batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 5, 5, 64)     0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 6, 6, 728)    0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 5, 5, 64)     256         activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 6, 6, 1024)   752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 2, 2, 64)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 6, 6, 1024)   4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 3, 3, 1024)   745472      add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 2, 2, 64)     0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 3, 3, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 3, 3, 1024)   4096        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 2, 2, 128)    73856       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 3, 3, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 2, 2, 128)    0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 3, 3, 1536)   1582080     add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 2, 2, 128)    512         activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 3, 3, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 2, 2, 128)    147584      batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 3, 3, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 2, 2, 128)    0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 3, 3, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 2, 2, 128)    512         activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 3, 3, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 1, 1, 128)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 3, 3, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1, 1, 128)    0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 3, 3, 32)     589856      block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 128)          0           dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 3, 3, 32)     0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          16512       flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 3, 3, 32)     128         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 32)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 128)          512         activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1, 1, 32)     0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 128)          0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 32)           0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            258         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ages_output (Dense)             (None, 1)            33          flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gender_output (Activation)      (None, 2)            0           dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 42,849,810\n",
      "Trainable params: 21,396,905\n",
      "Non-trainable params: 21,452,905\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mate/.virtualenvs/deeplearn_gpu/lib/python3.6/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "REAL_EPOCH = len(History.epoch)\n",
    "# print(y_train_gender)\n",
    "loss_names = [\"val_loss\", \"val_ages_output_loss\", \"val_gender_output_loss\",\n",
    "              \"ages_output_acc\", \"gender_output_acc\",\n",
    "             \"val_gender_output_acc\", \"val_ages_output_acc\"]\n",
    "\n",
    "epoch_save = np.arange(0, REAL_EPOCH)\n",
    "val_loss_save = History.history[loss_names[0]]\n",
    "val_ages_out_save = History.history[loss_names[1]]\n",
    "val_gender_out_save = History.history[loss_names[2]]\n",
    "\n",
    "loss_file = open(project_path + \"fine_loss_save.csv\", \"w\")\n",
    "\n",
    "head = \"epoch_num\"\n",
    "\n",
    "for lo in loss_names:\n",
    "    head += \",\" +lo\n",
    "head +=\"\\n\"\n",
    "loss_file.write(head)\n",
    "\n",
    "for i in range(REAL_EPOCH):\n",
    "    line = \"\"\n",
    "    line += str(i)\n",
    "    for lo in loss_names:\n",
    "        line += \",{}\".format(History.history[lo][i])\n",
    "        \n",
    "    line +=\"\\n\"\n",
    "    loss_file.write(line)\n",
    "    \n",
    "#     loss_file.write(\"{},{},{},{}\\n\".format(i, val_loss_save[i], val_ages_out_save[i], val_gender_out_save[i]))\n",
    "\n",
    "loss_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path = \"/home/mate/develop/PycharmProjects/GeFace/\"\n",
    "df = pd.read_csv(csv_path+\"fine_loss_save.csv\")\n",
    "\n",
    "header = list(df)\n",
    "REAL_EPOCH = len(df)\n",
    "REAL_EPOCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = [\"val_ages_output_loss\", \"val_gender_output_acc\"]\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "(fig, ax) = plt.subplots(2, 1, figsize=(8,8))\n",
    "\n",
    "for (i, l) in enumerate(losses):\n",
    "    ax[i].set_title(\"Loss for {}\".format(l))\n",
    "    ax[i].set_xlabel(\"Epochs\")\n",
    "    ax[i].set_ylabel(\"Loss\")\n",
    "  \n",
    "    ax[i].plot(np.arange(0, REAL_EPOCH), df[l],label=l)\n",
    "    ax[i].legend()\n",
    "    \n",
    "#     ax[0].set_ylim([0,1])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(csv_path+\"/val_Xceptionloss.png\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
