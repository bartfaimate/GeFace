{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import sys\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chdir. it depends on the platform\n",
    "if sys.platform == 'linux':\n",
    "    # if os is linux cd to\n",
    "    project_path = \"/home/mate/develop/PycharmProjects/GeFace/\"\n",
    "elif sys.platform is 'windows':\n",
    "    pass\n",
    "else:\n",
    "    pass\n",
    "\n",
    "os.chdir(project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mate/develop/PycharmProjects/GeFace\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(os.getcwd())\n",
    "    # Open CSV with all informations\n",
    "    csv_file = pd.read_csv(\"faces_colored/faces_correct.csv\",delimiter = ',', encoding = \"ISO-8859-1\", engine='python')\n",
    "    pd.set_option('display.max_columns', 100)\n",
    "except (FileNotFoundError):\n",
    "    print(\"CSV file not found\")\n",
    "    current_path = os.getcwd()\n",
    "    print(\"Current path is \" + current_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nr</th>\n",
       "      <th>age</th>\n",
       "      <th>full_path</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>01/nm0000001_rm124825600_1899-5-10_1968.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>01/nm0000001_rm3343756032_1899-5-10_1970.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>01/nm0000001_rm577153792_1899-5-10_1968.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>02/nm0000002_rm1075631616_1924-9-16_1991.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>80</td>\n",
       "      <td>02/nm0000002_rm1346607872_1924-9-16_2004.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nr  age                                     full_path  gender\n",
       "0   0   69   01/nm0000001_rm124825600_1899-5-10_1968.jpg     1.0\n",
       "1   1   71  01/nm0000001_rm3343756032_1899-5-10_1970.jpg     1.0\n",
       "2   2   69   01/nm0000001_rm577153792_1899-5-10_1968.jpg     1.0\n",
       "3   5   67  02/nm0000002_rm1075631616_1924-9-16_1991.jpg     0.0\n",
       "4   6   80  02/nm0000002_rm1346607872_1924-9-16_2004.jpg     0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = csv_file.drop(columns=[\"nr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>full_path</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69</td>\n",
       "      <td>01/nm0000001_rm124825600_1899-5-10_1968.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71</td>\n",
       "      <td>01/nm0000001_rm3343756032_1899-5-10_1970.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69</td>\n",
       "      <td>01/nm0000001_rm577153792_1899-5-10_1968.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67</td>\n",
       "      <td>02/nm0000002_rm1075631616_1924-9-16_1991.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80</td>\n",
       "      <td>02/nm0000002_rm1346607872_1924-9-16_2004.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age                                     full_path  gender\n",
       "0   69   01/nm0000001_rm124825600_1899-5-10_1968.jpg     1.0\n",
       "1   71  01/nm0000001_rm3343756032_1899-5-10_1970.jpg     1.0\n",
       "2   69   01/nm0000001_rm577153792_1899-5-10_1968.jpg     1.0\n",
       "3   67  02/nm0000002_rm1075631616_1924-9-16_1991.jpg     0.0\n",
       "4   80  02/nm0000002_rm1346607872_1924-9-16_2004.jpg     0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset for testing the network\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "proba_df = df.head(1000)\n",
    "\n",
    "# Randomize but always the same random numbers\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "# shuffle rows\n",
    "proba_df = shuffle(proba_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>full_path</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>33</td>\n",
       "      <td>62/nm0000062_rm360689664_1935-1-8_1968.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>37</td>\n",
       "      <td>84/nm0000084_rm3788019968_1965-12-31_2002.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>37</td>\n",
       "      <td>84/nm0000084_rm3838351616_1965-12-31_2002.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>26</td>\n",
       "      <td>79/nm0000079_rm2756104448_1940-9-5_1966.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>57</td>\n",
       "      <td>56/nm0000056_rm1541314816_1925-1-26_1982.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age                                      full_path  gender\n",
       "521   33     62/nm0000062_rm360689664_1935-1-8_1968.jpg     1.0\n",
       "737   37  84/nm0000084_rm3788019968_1965-12-31_2002.jpg     0.0\n",
       "740   37  84/nm0000084_rm3838351616_1965-12-31_2002.jpg     0.0\n",
       "660   26    79/nm0000079_rm2756104448_1940-9-5_1966.jpg     0.0\n",
       "411   57   56/nm0000056_rm1541314816_1925-1-26_1982.jpg     1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 700 | valid: 200 | test: 100\n"
     ]
    }
   ],
   "source": [
    "# calculate test train valid data numbers\n",
    "test_num = int(np.floor(0.1 * proba_df.shape[0]))\n",
    "valid_num = int(np.floor(0.2 * proba_df.shape[0]))\n",
    "train_num = int(proba_df.shape[0] - test_num - valid_num)\n",
    "print(\"train: {} | valid: {} | test: {}\".format(train_num, valid_num, test_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the data into train valid and test data\n",
    "train_data = proba_df.iloc[0:train_num, :]\n",
    "train_data.shape\n",
    "\n",
    "valid_data = proba_df.iloc[train_num:train_num + valid_num, :]\n",
    "valid_data.shape\n",
    "\n",
    "test_data = proba_df.iloc[ train_num+valid_num:, :]\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'faces_colored/92/nm0000092_rm2154539520_1939-10-27_1975.jpg'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = \"faces_colored/\"\n",
    "x_train_p = image_path + train_data['full_path'].values\n",
    "x_valid_p = image_path + valid_data['full_path'].values\n",
    "x_test_p = image_path + test_data['full_path'].values\n",
    "\n",
    "# x_train_l = image_path + train_data['age'].values\n",
    "# x_valid_l = image_path + train_data['age'].values\n",
    "# x_test_l = image_path + train_data['age'].values\n",
    "\n",
    "x_test_p.shape\n",
    "x_test_p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the ages\n",
    "y_train = train_data['age'].values\n",
    "y_valid = valid_data['age'].values\n",
    "y_test = test_data['age'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy train, valid, test data into a new folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>full_path</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>33</td>\n",
       "      <td>62/nm0000062_rm360689664_1935-1-8_1968.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>37</td>\n",
       "      <td>84/nm0000084_rm3788019968_1965-12-31_2002.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>37</td>\n",
       "      <td>84/nm0000084_rm3838351616_1965-12-31_2002.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>26</td>\n",
       "      <td>79/nm0000079_rm2756104448_1940-9-5_1966.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>57</td>\n",
       "      <td>56/nm0000056_rm1541314816_1925-1-26_1982.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age                                      full_path  gender\n",
       "521   33     62/nm0000062_rm360689664_1935-1-8_1968.jpg     1.0\n",
       "737   37  84/nm0000084_rm3788019968_1965-12-31_2002.jpg     0.0\n",
       "740   37  84/nm0000084_rm3838351616_1965-12-31_2002.jpg     0.0\n",
       "660   26    79/nm0000079_rm2756104448_1940-9-5_1966.jpg     0.0\n",
       "411   57   56/nm0000056_rm1541314816_1925-1-26_1982.jpg     1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from shutil import copyfile, copy2\n",
    "try:\n",
    "    os.mkdir(\"test_face\")\n",
    "except FileExistsError:\n",
    "    print(\"test_face Direcotry exist\")\n",
    "    \n",
    "# training \n",
    "try:\n",
    "    os.mkdir(\"train_face\")\n",
    "    # create directory structure\n",
    "    \n",
    "    \n",
    "except FileExistsError:\n",
    "    print(\"train_face Direcotry exist\")\n",
    "    \n",
    "for i in range(100):\n",
    "    try:\n",
    "        if i < 10:\n",
    "        \n",
    "            os.mkdir(\"train_face/0\" + str(i))\n",
    "        else:\n",
    "            os.mkdir(\"train_face/\" + str(i))\n",
    "    except FileExistsError:\n",
    "        continue\n",
    "i = 0\n",
    "dest_path = \"train_face/\"+train_data['full_path'].values\n",
    "for p in x_train_p:\n",
    "    \n",
    "    copy2(p, dest_path[i])\n",
    "    i += 1\n",
    "#     print(\"train_face/\"+train_data['full_path'].values)\n",
    "#     print(dest_path[i])\n",
    "\n",
    "# validation\n",
    "try:\n",
    "    os.mkdir(\"valid_face\")\n",
    "    # create directory structure\n",
    "    \n",
    "    for i in range(100):\n",
    "        try:\n",
    "            if i < 10:\n",
    "            \n",
    "                os.mkdir(\"valid_face/0\" + str(i))\n",
    "            else:\n",
    "                os.mkdir(\"valid_face/\" + str(i))\n",
    "        except FileExistsError:\n",
    "            continue\n",
    "except FileExistsError:\n",
    "    print(\"valid_face Direcotry exist\")\n",
    "    \n",
    "i = 0\n",
    "dest_path = \"valid_face/\"+valid_data['full_path'].values\n",
    "for p in x_valid_p:\n",
    "    \n",
    "    copy2(p, dest_path[i])\n",
    "    i += 1\n",
    "#     print(\"train_face/\"+train_data['full_path'].values)\n",
    "#     print(dest_path[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/mate/.virtualenvs/deeplearn_gpu/lib/python3.6/site-packages/ipykernel_launcher.py:14: UserWarning: matplotlib.pyplot as already been imported, this call will have no effect.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "import sys\n",
    "import os\n",
    "import PIL\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.applications import *\n",
    "from keras.models import Model, Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    " \n",
    "# import the necessary packages\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from pyimagesearch.smallervggnet import SmallerVGGNet\n",
    "import matplotlib.pyplot as plt\n",
    "# from imutils import paths\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallerVGGNet:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes):\n",
    "        # initialize the model along with the input shape to be\n",
    "        # \"channels last\" and the channels dimension itself\n",
    "        model = Sequential()\n",
    "        inputShape = (height, width, depth)\n",
    "        chanDim = -1\n",
    " \n",
    "        # if we are using \"channels first\", update the input shape\n",
    "        # and channels dimension\n",
    "        if K.image_data_format() == \"channels_first\":\n",
    "            inputShape = (depth, height, width)\n",
    "            chanDim = 1\n",
    "            \n",
    "        # CONV => RELU => POOL\n",
    "        model.add(Conv2D(32, (3, 3), padding=\"same\",\n",
    "            input_shape=inputShape))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        # (CONV => RELU) * 2 => POOL\n",
    "        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        # (CONV => RELU) * 2 => POOL\n",
    "        model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        # first (and only) set of FC => RELU layers\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1024))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "        print(\"mknlm\")\n",
    "        # softmax classifier\n",
    "        model.add(Dense(classes))\n",
    "        print(\"ffjseoijwojdowq\")\n",
    "        model.add(Activation(\"softmax\"))\n",
    " \n",
    "        # return the constructed network architecture\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix seed for reproducible results (only works on CPU, not GPU)\n",
    "seed = 42\n",
    "np.random.seed(seed=seed)\n",
    "tf.set_random_seed(seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the number of epochs to train for, initial learning rate,\n",
    "# batch size, and image dimensions\n",
    "EPOCHS = 1\n",
    "INIT_LR = 1e-3\n",
    "BS = 32\n",
    "IMAGE_DIMS = (96, 96, 3)\n",
    " \n",
    "# initialize the data and labels\n",
    "train_x = []\n",
    "train_y = []\n",
    "\n",
    "valid_x = []\n",
    "valid_y = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "# loop over the input images\n",
    "i = 0\n",
    "train_y = y_train\n",
    "for imagePath in x_train_p:\n",
    "    # load the image, pre-process it, and store it in the data list\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = img_to_array(image)\n",
    "    train_x.append(image)\n",
    "    \n",
    "# valid\n",
    "# loop over the input images\n",
    "i = 0\n",
    "valid_y = y_valid\n",
    "for imagePath in x_valid_p:\n",
    "    # load the image, pre-process it, and store it in the data list\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = img_to_array(image)\n",
    "    valid_x.append(image)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_y.astype(\"str\")\n",
    "valid_y = valid_y.astype(\"str\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] data matrix: 151.20MB\n",
      "[INFO] data matrix: 43.20MB\n",
      "700\n",
      "700\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "train_x = np.array(train_x, dtype=\"float\") / 255.0\n",
    "train_y = np.array(train_y)\n",
    "# print(train_y)\n",
    "print(\"[INFO] data matrix: {:.2f}MB\".format(\n",
    "\ttrain_x.nbytes / (1024 * 1000.0)))\n",
    " \n",
    "# binarize the labels\n",
    "lb = LabelBinarizer()\n",
    "train_y = lb.fit_transform(train_y)\n",
    " \n",
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "valid_x = np.array(valid_x, dtype=\"float\") / 255.0\n",
    "valid_y = np.array(valid_y)\n",
    "print(\"[INFO] data matrix: {:.2f}MB\".format(\n",
    "\tvalid_x.nbytes / (1024 * 1000.0)))\n",
    " \n",
    "# binarize the labels\n",
    "# lb1 = LabelBinarizer()\n",
    "valid_y = lb.transform(valid_y)\n",
    "\n",
    "print(len(train_x))\n",
    "print(len(train_y))\n",
    "print(len(valid_x))\n",
    "print(len(valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
    "\theight_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "\thorizontal_flip=True, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "[INFO] compiling model...\n",
      "mknlm\n",
      "ffjseoijwojdowq\n",
      "[INFO] training network...\n",
      "Epoch 1/50\n",
      "21/21 [==============================] - 8s 372ms/step - loss: 5.6412 - acc: 0.0298 - val_loss: 6.7589 - val_acc: 0.0600\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 3s 150ms/step - loss: 4.7192 - acc: 0.0657 - val_loss: 6.1751 - val_acc: 0.0850\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 3s 139ms/step - loss: 4.5736 - acc: 0.0568 - val_loss: 5.8923 - val_acc: 0.0450\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 3s 132ms/step - loss: 4.3967 - acc: 0.0806 - val_loss: 5.3069 - val_acc: 0.0950\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 3s 134ms/step - loss: 4.2121 - acc: 0.0884 - val_loss: 5.4559 - val_acc: 0.0750\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 3s 126ms/step - loss: 4.1672 - acc: 0.0910 - val_loss: 5.6964 - val_acc: 0.0600\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 3s 128ms/step - loss: 3.9927 - acc: 0.1133 - val_loss: 5.4369 - val_acc: 0.0650\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 3s 131ms/step - loss: 3.9957 - acc: 0.1059 - val_loss: 5.4846 - val_acc: 0.0850\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 3s 130ms/step - loss: 3.8419 - acc: 0.1320 - val_loss: 5.5996 - val_acc: 0.1150\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 3s 132ms/step - loss: 3.9009 - acc: 0.1327 - val_loss: 7.1750 - val_acc: 0.0950\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 3s 120ms/step - loss: 4.1040 - acc: 0.1027 - val_loss: 7.1083 - val_acc: 0.0500\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 3s 121ms/step - loss: 3.7866 - acc: 0.1329 - val_loss: 5.5340 - val_acc: 0.0700\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 3s 121ms/step - loss: 3.7038 - acc: 0.1641 - val_loss: 5.6363 - val_acc: 0.1100\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 3s 129ms/step - loss: 3.6226 - acc: 0.1569 - val_loss: 5.2067 - val_acc: 0.1100\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 3s 125ms/step - loss: 3.5950 - acc: 0.1705 - val_loss: 4.5950 - val_acc: 0.1250\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 3s 135ms/step - loss: 3.3991 - acc: 0.1760 - val_loss: 4.4732 - val_acc: 0.1700\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 3s 146ms/step - loss: 3.4115 - acc: 0.1826 - val_loss: 4.6376 - val_acc: 0.1800\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 3s 144ms/step - loss: 3.0423 - acc: 0.2766 - val_loss: 4.3688 - val_acc: 0.2000\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 3s 138ms/step - loss: 3.0063 - acc: 0.2543 - val_loss: 4.5734 - val_acc: 0.1950\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 3s 138ms/step - loss: 3.0518 - acc: 0.2649 - val_loss: 4.4298 - val_acc: 0.1200\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 3s 132ms/step - loss: 2.8579 - acc: 0.2853 - val_loss: 4.2888 - val_acc: 0.1700\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 3s 138ms/step - loss: 2.9441 - acc: 0.2566 - val_loss: 5.1763 - val_acc: 0.1000\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 3s 136ms/step - loss: 2.8042 - acc: 0.2604 - val_loss: 5.2792 - val_acc: 0.0900\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 3s 137ms/step - loss: 2.8371 - acc: 0.2773 - val_loss: 4.4820 - val_acc: 0.1650\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 3s 138ms/step - loss: 2.6634 - acc: 0.3289 - val_loss: 4.5398 - val_acc: 0.1750\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 3s 133ms/step - loss: 2.6266 - acc: 0.3060 - val_loss: 4.8412 - val_acc: 0.1950\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 3s 136ms/step - loss: 2.5421 - acc: 0.3429 - val_loss: 4.5787 - val_acc: 0.2150\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 3s 137ms/step - loss: 2.3897 - acc: 0.3816 - val_loss: 4.7725 - val_acc: 0.1900\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 3s 131ms/step - loss: 2.2799 - acc: 0.4039 - val_loss: 4.6934 - val_acc: 0.1950\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 3s 131ms/step - loss: 2.3545 - acc: 0.3433 - val_loss: 4.6612 - val_acc: 0.2350\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 3s 131ms/step - loss: 2.2857 - acc: 0.4028 - val_loss: 4.4829 - val_acc: 0.2100\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 3s 129ms/step - loss: 2.2612 - acc: 0.3837 - val_loss: 4.5358 - val_acc: 0.2400\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 3s 124ms/step - loss: 2.1634 - acc: 0.3931 - val_loss: 4.5984 - val_acc: 0.2150\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 3s 124ms/step - loss: 2.2376 - acc: 0.3952 - val_loss: 4.7689 - val_acc: 0.2000\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 3s 125ms/step - loss: 1.9543 - acc: 0.4694 - val_loss: 4.7549 - val_acc: 0.2250\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 3s 125ms/step - loss: 2.2887 - acc: 0.3703 - val_loss: 4.6573 - val_acc: 0.2450\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 3s 125ms/step - loss: 2.1135 - acc: 0.4096 - val_loss: 4.9024 - val_acc: 0.2350\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 3s 124ms/step - loss: 2.0650 - acc: 0.4252 - val_loss: 5.2072 - val_acc: 0.2000\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 3s 124ms/step - loss: 2.0611 - acc: 0.4437 - val_loss: 4.7907 - val_acc: 0.2250\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 3s 124ms/step - loss: 1.9764 - acc: 0.4647 - val_loss: 4.7164 - val_acc: 0.2250\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 3s 126ms/step - loss: 1.9553 - acc: 0.4503 - val_loss: 4.7242 - val_acc: 0.2300\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 3s 129ms/step - loss: 1.6882 - acc: 0.5194 - val_loss: 4.6224 - val_acc: 0.2300\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 3s 130ms/step - loss: 1.6929 - acc: 0.5132 - val_loss: 4.7486 - val_acc: 0.2150\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 3s 144ms/step - loss: 1.6728 - acc: 0.5011 - val_loss: 4.9086 - val_acc: 0.2000\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 3s 139ms/step - loss: 1.6577 - acc: 0.5253 - val_loss: 4.6269 - val_acc: 0.2350\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 3s 129ms/step - loss: 1.5606 - acc: 0.5451 - val_loss: 4.9157 - val_acc: 0.1500\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 3s 132ms/step - loss: 1.5846 - acc: 0.5568 - val_loss: 4.6221 - val_acc: 0.2400\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 3s 128ms/step - loss: 1.4203 - acc: 0.5855 - val_loss: 4.9158 - val_acc: 0.1800\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 3s 136ms/step - loss: 1.5036 - acc: 0.5423 - val_loss: 4.9807 - val_acc: 0.2050\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 3s 140ms/step - loss: 1.5381 - acc: 0.5540 - val_loss: 4.8350 - val_acc: 0.2150\n",
      "[INFO] serializing network...\n",
      "[INFO] serializing label binarizer...\n"
     ]
    }
   ],
   "source": [
    "# initialize the model\n",
    "print(len(lb.classes_))\n",
    "print(\"[INFO] compiling model...\")\n",
    "model = SmallerVGGNet.build(width=IMAGE_DIMS[1], height=IMAGE_DIMS[0],\n",
    "\tdepth=IMAGE_DIMS[2], classes=len(lb.classes_))\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    " \n",
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "H = model.fit_generator(\n",
    " \taug.flow(train_x, train_y, batch_size=BS),\n",
    "\tvalidation_data=(valid_x, valid_y),\n",
    "\tsteps_per_epoch=len(train_x) // BS,\n",
    "\tepochs=50, verbose=1)\n",
    "\n",
    "\n",
    "# save the model to disk\n",
    "print(\"[INFO] serializing network...\")\n",
    "model.save(project_path+\"model.hdf5\")\n",
    " \n",
    "# save the label binarizer to disk\n",
    "print(\"[INFO] serializing label binarizer...\")\n",
    "f = open(project_path+\"label.label\", \"wb\")\n",
    "f.write(pickle.dumps(lb))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = 50\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.savefig(project_path+\"loss.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.1) /home/mate/opencv-3.4.1/modules/core/src/ocl.cpp:5358: error: (-220) OpenCL error CL_MEM_OBJECT_ALLOCATION_FAILURE (-4) during call: clEnqueueWriteBuffer(q, (cl_mem)u->handle, CL_TRUE, dstrawofs, total, alignedPtr.getAlignedPtr(), 0, 0, 0) in function upload\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-c80055d9c79f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_cascade\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mbb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(3.4.1) /home/mate/opencv-3.4.1/modules/core/src/ocl.cpp:5358: error: (-220) OpenCL error CL_MEM_OBJECT_ALLOCATION_FAILURE (-4) during call: clEnqueueWriteBuffer(q, (cl_mem)u->handle, CL_TRUE, dstrawofs, total, alignedPtr.getAlignedPtr(), 0, 0, 0) in function upload\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load the image\n",
    "image = cv2.imread(project_path+\"orki.jpg\")\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('detector/haarcascade_frontalface_default.xml')\n",
    "\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n",
    "\n",
    "bb = []\n",
    "i = 0\n",
    "for (x,y,w,h) in faces:\n",
    "    bb.append([w * h, i])\n",
    "    #cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    " #   roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = image[y:y+h, x:x+w]\n",
    "    i += 1\n",
    "    print(i)\n",
    "    break\n",
    "#     cv2.imshow(\"faces/\"+path, roi_color)\n",
    "#         plt.figure()\n",
    "#         plt.imshow(roi_color)\n",
    "\n",
    "output = roi_color.copy()\n",
    "\n",
    "\n",
    "# pre-process the image for classification\n",
    "image = cv2.resize(image, (96, 96))\n",
    "image = image.astype(\"float\") / 255.0\n",
    "image = img_to_array(image)\n",
    "image = np.expand_dims(image, axis=0)\n",
    "\n",
    "# load the trained convolutional neural network and the label\n",
    "# binarizer\n",
    "print(\"[INFO] loading network...\")\n",
    "model = load_model(project_path+\"model.hdf5\")\n",
    "lb = pickle.loads(open(project_path+\"label.label\", \"rb\").read())\n",
    " \n",
    "# classify the input image\n",
    "print(\"[INFO] classifying image...\")\n",
    "proba = model.predict(image)[0]\n",
    "idx = np.argmax(proba)\n",
    "label = lb.classes_[idx]\n",
    "print(label)\n",
    "# build the label and draw the label on the image\n",
    "# label = \"{}: {:.2f}% ({})\".format(label, proba[idx] * 100, correct)\n",
    "# output = imutils.resize(output, width=400)\n",
    "# cv2.putText(output, label, (10, 25),  cv2.FONT_HERSHEY_SIMPLEX,\n",
    "# \t0.7, (0, 255, 0), 2)\n",
    " \n",
    "# show the output image\n",
    "print(\"[INFO] {}\".format(label))\n",
    "plt.imshow(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters for model\n",
    "nb_classes = 101  # number of classes\n",
    "based_model_last_block_layer_number = 126  # value is based on based model selected.\n",
    "img_width, img_height = 96, 96  # change based on the shape/structure of your images\n",
    "batch_size = 32  # try 4, 8, 16, 32, 64, 128, 256 dependent on CPU/GPU memory capacity (powers of 2 values).\n",
    "nb_epoch = 100  # number of iteration the algorithm gets trained.\n",
    "learn_rate = 1e-4  # sgd learning rate\n",
    "momentum = 0.9  # sgd momentum to avoid local minimum\n",
    "transformation_ratio = 0.05  # how aggressive will be the data augmentation/transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_data_dir, validation_data_dir, model_path):\n",
    "    # create model directory if not exist\n",
    "    try:\n",
    "        os.mkdir(model_path)\n",
    "    except:\n",
    "        print(model_path, \"folder exist\")\n",
    "        \n",
    "    # Pre-Trained CNN Model using imagenet dataset for pre-trained weights\n",
    "    base_model = Xception(input_shape=(img_width, img_height, 3), weights='imagenet', include_top=True)\n",
    "\n",
    "    # Top Model Block\n",
    "    x = base_model.output\n",
    "#     x = MaxPooling1D()(x)\n",
    "    predictions = Dense(nb_classes, activation='softmax')(x)\n",
    "\n",
    "    # add your top layer block to your base model\n",
    "    model = Model(base_model.input, predictions)\n",
    "    print(model.summary())\n",
    "\n",
    "    # # let's visualize layer names and layer indices to see how many layers/blocks to re-train\n",
    "    # # uncomment when choosing based_model_last_block_layer\n",
    "    # for i, layer in enumerate(model.layers):\n",
    "    #     print(i, layer.name)\n",
    "\n",
    "    # first: train only the top layers (which were randomly initialized)\n",
    "    # i.e. freeze all layers of the based model that is already pre-trained.\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Read Data and Augment it: Make sure to select augmentations that are appropriate to your images.\n",
    "    # To save augmentations un-comment save lines and add to your flow parameters.\n",
    "    train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "                                       rotation_range=transformation_ratio,\n",
    "                                       shear_range=transformation_ratio,\n",
    "                                       zoom_range=transformation_ratio,\n",
    "                                       cval=transformation_ratio,\n",
    "                                       horizontal_flip=True,\n",
    "#                                        vertical_flip=True,\n",
    "                                      )\n",
    "\n",
    "    validation_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    os.makedirs(os.path.join(os.path.abspath(train_data_dir), 'preview'), exist_ok=True)\n",
    "    train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                        target_size=(img_width, img_height),\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        class_mode='categorical')\n",
    "    # save_to_dir=os.path.join(os.path.abspath(train_data_dir), '../preview')\n",
    "    # save_prefix='aug',\n",
    "    # save_format='jpeg')\n",
    "    # use the above 3 commented lines if you want to save and look at how the data augmentations look like\n",
    "\n",
    "    validation_generator = validation_datagen.flow_from_directory(validation_data_dir,\n",
    "                                                                  target_size=(img_width, img_height),\n",
    "                                                                  batch_size=batch_size,\n",
    "                                                                  class_mode='categorical')\n",
    "\n",
    "    model.compile(optimizer='nadam',\n",
    "                  loss='categorical_crossentropy',  # categorical_crossentropy if multi-class classifier\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # save weights of best training epoch: monitor either val_loss or val_acc\n",
    "\n",
    "    top_weights_path = os.path.join(os.path.abspath(model_path), 'top_model_weights.h5')\n",
    "    print(top_weights_path)\n",
    "    callbacks_list = [\n",
    "        ModelCheckpoint(top_weights_path, monitor='val_acc', verbose=1, save_best_only=True),\n",
    "        EarlyStopping(monitor='val_acc', patience=5, verbose=0),\n",
    "    ]\n",
    "\n",
    "    # Train Simple CNN\n",
    "    model.fit_generator(train_generator,\n",
    "#                         samples_per_epoch=train_generator.nb_sample,\n",
    "                        samples_per_epoch=batch_size,\n",
    "                        nb_epoch=int(nb_epoch / 5),\n",
    "                        validation_data=validation_generator,\n",
    "#                         nb_val_samples=int(validation_generator),\n",
    "                        nb_val_samples=batch_size,\n",
    "                        callbacks=callbacks_list,\n",
    "                       )\n",
    "\n",
    "    # verbose\n",
    "    print(\"\\nStarting to Fine Tune Model\\n\")\n",
    "\n",
    "    # add the best weights from the train top model\n",
    "    # at this point we have the pre-train weights of the base model and the trained weight of the new/added top model\n",
    "    # we re-load model weights to ensure the best epoch is selected and not the last one.\n",
    "    model.load_weights(top_weights_path)\n",
    "\n",
    "    # based_model_last_block_layer_number points to the layer in your model you want to train.\n",
    "    # For example if you want to train the last block of a 19 layer VGG16 model this should be 15\n",
    "    # If you want to train the last Two blocks of an Inception model it should be 172\n",
    "    # layers before this number will used the pre-trained weights, layers above and including this number\n",
    "    # will be re-trained based on the new data.\n",
    "    for layer in model.layers[:based_model_last_block_layer_number]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[based_model_last_block_layer_number:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # compile the model with a SGD/momentum optimizer\n",
    "    # and a very slow learning rate.\n",
    "    model.compile(optimizer='nadam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # save weights of best training epoch: monitor either val_loss or val_acc\n",
    "    final_weights_path = os.path.join(os.path.abspath(model_path), 'model_weights.h5')\n",
    "    callbacks_list = [\n",
    "        ModelCheckpoint(final_weights_path, monitor='val_acc', verbose=1, save_best_only=True),\n",
    "        EarlyStopping(monitor='val_loss', patience=5, verbose=0)\n",
    "    ]\n",
    "\n",
    "    # fine-tune the model\n",
    "    model.fit_generator(train_generator,\n",
    "#                         samples_per_epoch=train_generator.nb_sample,\n",
    "                        samples_per_epoch=batch_size,\n",
    "                        nb_epoch=nb_epoch,\n",
    "                        validation_data=validation_generator,\n",
    "#                         nb_val_samples=validation_generator.nb_sample,\n",
    "#                         nb_val_samples=validation_generator[nb_sample],\n",
    "                        nb_val_samples=batch_size,\n",
    "                        callbacks=callbacks_list,\n",
    "                       )\n",
    "\n",
    "    # save model\n",
    "    model_json = model.to_json()\n",
    "    with open(os.path.join(os.path.abspath(model_path), 'model.json'), 'w') as json_file:\n",
    "        json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mate/develop/PycharmProjects/GeFace/faces_model folder exist\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 96, 96, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 47, 47, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 47, 47, 32)   128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 47, 47, 32)   0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 45, 45, 64)   18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 45, 45, 64)   256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 45, 45, 64)   0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 45, 45, 128)  8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 45, 45, 128)  512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 45, 45, 128)  0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 45, 45, 128)  17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 45, 45, 128)  512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 23, 23, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 23, 23, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 23, 23, 128)  512         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 23, 23, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 23, 23, 128)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 23, 23, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 23, 23, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 23, 23, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 23, 23, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 23, 23, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 12, 12, 256)  32768       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 12, 12, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 12, 12, 256)  1024        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 12, 12, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 12, 12, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 12, 12, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 12, 12, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 12, 12, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 12, 12, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 12, 12, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 6, 6, 728)    186368      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 6, 6, 728)    0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 6, 6, 728)    2912        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 6, 6, 728)    0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 6, 6, 728)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 6, 6, 728)    0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 6, 6, 728)    0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 6, 6, 728)    0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 6, 6, 728)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 6, 6, 728)    0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 6, 6, 728)    0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 6, 6, 728)    0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 6, 6, 728)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 6, 6, 728)    0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 6, 6, 728)    0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 6, 6, 728)    0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 6, 6, 728)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 6, 6, 728)    0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 6, 6, 728)    0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 6, 6, 728)    0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 6, 6, 728)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 6, 6, 728)    0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 6, 6, 728)    0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 6, 6, 728)    0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 6, 6, 728)    0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 6, 6, 728)    536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 6, 6, 728)    2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 6, 6, 728)    0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 6, 6, 728)    536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 6, 6, 728)    2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 6, 6, 728)    0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 6, 6, 728)    0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 6, 6, 728)    536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 6, 6, 728)    2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 6, 6, 728)    0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 6, 6, 728)    536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 6, 6, 728)    2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 6, 6, 728)    0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 6, 6, 728)    0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 6, 6, 728)    536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 6, 6, 728)    2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 6, 6, 728)    0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 6, 6, 728)    536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 6, 6, 728)    2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 6, 6, 728)    0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 6, 6, 728)    0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 6, 6, 1024)   752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 6, 6, 1024)   4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 3, 3, 1024)   745472      add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 3, 3, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 3, 3, 1024)   4096        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 3, 3, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 3, 3, 1536)   1582080     add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 3, 3, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 3, 3, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 3, 3, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 3, 3, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 3, 3, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 1000)         2049000     avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 101)          101101      predictions[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 23,011,581\n",
      "Trainable params: 22,957,053\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Found 700 images belonging to 101 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images belonging to 100 classes.\n",
      "/home/mate/develop/PycharmProjects/GeFace/faces_model/top_model_weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mate/.virtualenvs/deeplearn_gpu/lib/python3.6/site-packages/ipykernel_launcher.py:79: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/home/mate/.virtualenvs/deeplearn_gpu/lib/python3.6/site-packages/ipykernel_launcher.py:79: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=<keras_pre..., callbacks=[<keras.ca..., steps_per_epoch=1, epochs=20, validation_steps=32)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_3 to have shape (101,) but got array with shape (100,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-a5b7dea9261f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train_face\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"valid_face\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"faces_model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-407c48f1f2d6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_data_dir, validation_data_dir, model_path)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;31m#                         nb_val_samples=int(validation_generator),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                         \u001b[0mnb_val_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m                        )\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/deeplearn_gpu/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/deeplearn_gpu/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/deeplearn_gpu/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    232\u001b[0m                             \u001b[0mval_enqueuer_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                             \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                             workers=0)\n\u001b[0m\u001b[1;32m    235\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                         \u001b[0;31m# No need for try/except because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/deeplearn_gpu/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/deeplearn_gpu/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1470\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m             verbose=verbose)\n\u001b[0m\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/deeplearn_gpu/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(model, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m    344\u001b[0m                                  \u001b[0;34m'or (x, y). Found: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m                                  str(generator_output))\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m             \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mouts_per_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/deeplearn_gpu/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtest_on_batch\u001b[0;34m(self, x, y, sample_weight)\u001b[0m\n\u001b[1;32m   1248\u001b[0m         x, y, sample_weights = self._standardize_user_data(\n\u001b[1;32m   1249\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m             sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/deeplearn_gpu/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/deeplearn_gpu/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_3 to have shape (101,) but got array with shape (100,)"
     ]
    }
   ],
   "source": [
    "train(\"train_face\", \"valid_face\", project_path + \"faces_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"faces_colored/06/nm0000006_rm221957120_1915-8-29_1974.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.i"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
