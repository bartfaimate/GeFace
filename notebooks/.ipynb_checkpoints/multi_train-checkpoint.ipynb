{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import sys\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chdir. it depends on the platform\n",
    "if sys.platform == 'linux':\n",
    "    # if os is linux cd to\n",
    "    project_path = \"/home/mate/develop/PycharmProjects/GeFace/\"\n",
    "    NUMBER_OF_DATA = 5000\n",
    "elif sys.platform is 'windows':\n",
    "    pass\n",
    "else:\n",
    "    pass\n",
    "\n",
    "os.chdir(project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mate/develop/PycharmProjects/GeFace\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(os.getcwd())\n",
    "    # Open CSV with all informations\n",
    "    csv_file = pd.read_csv(\"faces_colored/faces_correct.csv\",delimiter = ',', encoding = \"ISO-8859-1\", engine='python')\n",
    "    pd.set_option('display.max_columns', 100)\n",
    "except (FileNotFoundError):\n",
    "    print(\"CSV file not found\")\n",
    "    current_path = os.getcwd()\n",
    "    print(\"Current path is \" + current_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nr</th>\n",
       "      <th>age</th>\n",
       "      <th>full_path</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>01/nm0000001_rm124825600_1899-5-10_1968.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>01/nm0000001_rm3343756032_1899-5-10_1970.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>01/nm0000001_rm577153792_1899-5-10_1968.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>02/nm0000002_rm1075631616_1924-9-16_1991.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>80</td>\n",
       "      <td>02/nm0000002_rm1346607872_1924-9-16_2004.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nr  age                                     full_path  gender\n",
       "0   0   69   01/nm0000001_rm124825600_1899-5-10_1968.jpg     1.0\n",
       "1   1   71  01/nm0000001_rm3343756032_1899-5-10_1970.jpg     1.0\n",
       "2   2   69   01/nm0000001_rm577153792_1899-5-10_1968.jpg     1.0\n",
       "3   5   67  02/nm0000002_rm1075631616_1924-9-16_1991.jpg     0.0\n",
       "4   6   80  02/nm0000002_rm1346607872_1924-9-16_2004.jpg     0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = csv_file.drop(columns=[\"nr\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert 1.0 to m as male\n",
    "#         0.0 to f as female\n",
    "def mod(x):\n",
    "    if x == 1.0:\n",
    "        x = \"m\"\n",
    "    else:\n",
    "        x = \"f\"\n",
    "    return x\n",
    "\n",
    "df[\"gender\"] = df[\"gender\"].apply(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>full_path</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69</td>\n",
       "      <td>01/nm0000001_rm124825600_1899-5-10_1968.jpg</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71</td>\n",
       "      <td>01/nm0000001_rm3343756032_1899-5-10_1970.jpg</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69</td>\n",
       "      <td>01/nm0000001_rm577153792_1899-5-10_1968.jpg</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67</td>\n",
       "      <td>02/nm0000002_rm1075631616_1924-9-16_1991.jpg</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80</td>\n",
       "      <td>02/nm0000002_rm1346607872_1924-9-16_2004.jpg</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age                                     full_path gender\n",
       "0   69   01/nm0000001_rm124825600_1899-5-10_1968.jpg      m\n",
       "1   71  01/nm0000001_rm3343756032_1899-5-10_1970.jpg      m\n",
       "2   69   01/nm0000001_rm577153792_1899-5-10_1968.jpg      m\n",
       "3   67  02/nm0000002_rm1075631616_1924-9-16_1991.jpg      f\n",
       "4   80  02/nm0000002_rm1346607872_1924-9-16_2004.jpg      f"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset for testing the network\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "proba_df = df.head(NUMBER_OF_DATA)\n",
    "\n",
    "# Randomize but always the same random numbers\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "# shuffle rows\n",
    "proba_df = shuffle(proba_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>full_path</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>40</td>\n",
       "      <td>96/nm0000096_rm3342833408_1968-8-9_2008.jpg</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2586</th>\n",
       "      <td>42</td>\n",
       "      <td>02/nm0000102_rm798989056_1958-7-8_2000.jpg</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2653</th>\n",
       "      <td>54</td>\n",
       "      <td>04/nm0000104_rm1136508928_1960-8-10_2014.jpg</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>48</td>\n",
       "      <td>93/nm0000093_rm2604513536_1963-12-18_2011.jpg</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>31</td>\n",
       "      <td>81/nm0000081_rm1019988992_1938-7-20_1969.jpg</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age                                      full_path gender\n",
       "1501   40    96/nm0000096_rm3342833408_1968-8-9_2008.jpg      f\n",
       "2586   42     02/nm0000102_rm798989056_1958-7-8_2000.jpg      m\n",
       "2653   54   04/nm0000104_rm1136508928_1960-8-10_2014.jpg      m\n",
       "1055   48  93/nm0000093_rm2604513536_1963-12-18_2011.jpg      m\n",
       "705    31   81/nm0000081_rm1019988992_1938-7-20_1969.jpg      f"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 3500 | valid: 1000 | test: 500\n"
     ]
    }
   ],
   "source": [
    "# calculate test train valid data numbers\n",
    "test_num = int(np.floor(0.1 * proba_df.shape[0]))\n",
    "valid_num = int(np.floor(0.2 * proba_df.shape[0]))\n",
    "train_num = int(proba_df.shape[0] - test_num - valid_num)\n",
    "print(\"train: {} | valid: {} | test: {}\".format(train_num, valid_num, test_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (3500, 3) | valid: (1000, 3) | test: (500, 3)\n"
     ]
    }
   ],
   "source": [
    "# split the data into train valid and test data\n",
    "train_data = proba_df.iloc[0:train_num, :]\n",
    "\n",
    "valid_data = proba_df.iloc[train_num:train_num + valid_num, :]\n",
    "\n",
    "test_data = proba_df.iloc[ train_num+valid_num:, :]\n",
    "\n",
    "print(\"train: {} | valid: {} | test: {}\".format(train_data.shape, valid_data.shape, test_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'faces_colored/08/nm0000108_rm629315584_1959-3-18_2004.jpg'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = \"faces_colored/\"\n",
    "x_train_p = image_path + train_data['full_path'].values\n",
    "x_valid_p = image_path + valid_data['full_path'].values\n",
    "x_test_p = image_path + test_data['full_path'].values\n",
    "\n",
    "# x_train_l = image_path + train_data['age'].values\n",
    "# x_valid_l = image_path + train_data['age'].values\n",
    "# x_test_l = image_path + train_data['age'].values\n",
    "\n",
    "x_test_p.shape\n",
    "x_test_p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age: 3500  |  1000\n"
     ]
    }
   ],
   "source": [
    "# get the ages\n",
    "y_train_age = train_data['age'].values\n",
    "y_valid_age = valid_data['age'].values\n",
    "y_test_age = test_data['age'].values\n",
    "\n",
    "print(\"age:\" ,len(y_train_age), \" | \", len(y_valid_age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender: 3500  |  1000\n"
     ]
    }
   ],
   "source": [
    "y_train_gender = train_data['gender'].values\n",
    "y_valid_gender = valid_data['gender'].values\n",
    "y_test_gender = test_data['gender'].values\n",
    "print(\"gender:\", len(y_train_gender), \" | \", len(y_valid_gender))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy train, valid, test data into a new folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>full_path</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>40</td>\n",
       "      <td>96/nm0000096_rm3342833408_1968-8-9_2008.jpg</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2586</th>\n",
       "      <td>42</td>\n",
       "      <td>02/nm0000102_rm798989056_1958-7-8_2000.jpg</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2653</th>\n",
       "      <td>54</td>\n",
       "      <td>04/nm0000104_rm1136508928_1960-8-10_2014.jpg</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>48</td>\n",
       "      <td>93/nm0000093_rm2604513536_1963-12-18_2011.jpg</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>31</td>\n",
       "      <td>81/nm0000081_rm1019988992_1938-7-20_1969.jpg</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age                                      full_path gender\n",
       "1501   40    96/nm0000096_rm3342833408_1968-8-9_2008.jpg      f\n",
       "2586   42     02/nm0000102_rm798989056_1958-7-8_2000.jpg      m\n",
       "2653   54   04/nm0000104_rm1136508928_1960-8-10_2014.jpg      m\n",
       "1055   48  93/nm0000093_rm2604513536_1963-12-18_2011.jpg      m\n",
       "705    31   81/nm0000081_rm1019988992_1938-7-20_1969.jpg      f"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_face Direcotry exist\n",
      "train_face Direcotry exist\n",
      "valid_face Direcotry exist\n"
     ]
    }
   ],
   "source": [
    "from shutil import copyfile, copy2\n",
    "try:\n",
    "    os.mkdir(\"test_face\")\n",
    "except FileExistsError:\n",
    "    print(\"test_face Direcotry exist\")\n",
    "    \n",
    "# training \n",
    "try:\n",
    "    os.mkdir(\"train_face\")\n",
    "    # create directory structure\n",
    "    \n",
    "    \n",
    "except FileExistsError:\n",
    "    print(\"train_face Direcotry exist\")\n",
    "    \n",
    "for i in range(100):\n",
    "    try:\n",
    "        if i < 10:\n",
    "        \n",
    "            os.mkdir(\"train_face/0\" + str(i))\n",
    "        else:\n",
    "            os.mkdir(\"train_face/\" + str(i))\n",
    "    except FileExistsError:\n",
    "        continue\n",
    "i = 0\n",
    "dest_path = \"train_face/\"+train_data['full_path'].values\n",
    "for p in x_train_p:\n",
    "    \n",
    "    copy2(p, dest_path[i])\n",
    "    i += 1\n",
    "#     print(\"train_face/\"+train_data['full_path'].values)\n",
    "#     print(dest_path[i])\n",
    "\n",
    "# validation\n",
    "try:\n",
    "    os.mkdir(\"valid_face\")\n",
    "    # create directory structure\n",
    "    \n",
    "    for i in range(100):\n",
    "        try:\n",
    "            if i < 10:\n",
    "            \n",
    "                os.mkdir(\"valid_face/0\" + str(i))\n",
    "            else:\n",
    "                os.mkdir(\"valid_face/\" + str(i))\n",
    "        except FileExistsError:\n",
    "            continue\n",
    "except FileExistsError:\n",
    "    print(\"valid_face Direcotry exist\")\n",
    "    \n",
    "i = 0\n",
    "dest_path = \"valid_face/\"+valid_data['full_path'].values\n",
    "for p in x_valid_p:\n",
    "    \n",
    "    copy2(p, dest_path[i])\n",
    "    i += 1\n",
    "#     print(\"train_face/\"+train_data['full_path'].values)\n",
    "#     print(dest_path[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/mate/.virtualenvs/deeplearn_gpu/lib/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: matplotlib.pyplot as already been imported, this call will have no effect.\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "import sys\n",
    "import os\n",
    "import PIL\n",
    "# import the necessary packages\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import *\n",
    "from keras.applications import *\n",
    "from keras.models import Model, Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    " \n",
    "# import the necessary packages\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.preprocessing import LabelBinarizer, MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from pyimagesearch.smallervggnet import SmallerVGGNet\n",
    "import matplotlib.pyplot as plt\n",
    "# from imutils import paths\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceNet:\n",
    "    \n",
    "    @staticmethod\n",
    "    def build_ages_branch(inputs, numAges, finalAct=\"softmax\", chanDim=-1):\n",
    "        # utilize a lambda layer to convert the 3 channel input to a\n",
    "        # grayscale representation\n",
    "#         depth = inputs[2]\n",
    "#         height = inputs[0]\n",
    "#         width = inputs[1]\n",
    "#         #x = Lambda(lambda c: tf.image.rgb_to_grayscale(c))(inputs)\n",
    "#         inputShape = (height, width, depth)\n",
    "#         chanDim = -1\n",
    " \n",
    "#         # if we are using \"channels first\", update the input shape\n",
    "#         # and channels dimension\n",
    "#         if K.image_data_format() == \"channels_first\":\n",
    "#             inputShape = (depth, height, width)\n",
    "#             chanDim = 1\n",
    "            \n",
    "    \n",
    "#         x = Sequential() \n",
    "\n",
    "        padding = \"same\"\n",
    "        # CONV => RELU => POOL\n",
    "        x = Conv2D(32, (3, 3), padding=padding)(inputs) \n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=chanDim)(x)\n",
    "        x = MaxPooling2D(pool_size=(3, 3))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "        \n",
    "        # (CONV => RELU) * 2 => POOL\n",
    "        x = Conv2D(64, (3, 3), padding=padding)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=chanDim)(x)\n",
    "        x = Conv2D(64, (3, 3), padding=padding)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=chanDim)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    " \n",
    "        # (CONV => RELU) * 2 => POOL\n",
    "        x = Conv2D(128, (3, 3), padding=padding)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=chanDim)(x)\n",
    "        x = Conv2D(128, (3, 3), padding=padding)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=chanDim)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "        \n",
    "        # define a branch of output layers for the number of different\n",
    "        # ages\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(256)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(numAges)(x)\n",
    "        x = Activation(finalAct, name=\"ages_output\")(x)\n",
    " \n",
    "        # return the category prediction sub-network\n",
    "        return x\n",
    "    \n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def build_gender_branch(inputs, numGender, finalAct=\"softmax\", chanDim=-1):\n",
    "        padding = \"same\"\n",
    "        # CONV => RELU => POOL\n",
    "        x = Conv2D(16, (3, 3), padding=padding)(inputs)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=chanDim)(x)\n",
    "        x = MaxPooling2D(pool_size=(3, 3))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    " \n",
    "        # CONV => RELU => POOL\n",
    "        x = Conv2D(32, (3, 3), padding=padding)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=chanDim)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    " \n",
    "        # CONV => RELU => POOL\n",
    "        x = Conv2D(32, (3, 3), padding=padding)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=chanDim)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "        \n",
    "        # define a branch of output layers for the number of different\n",
    "        # genders\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(128)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(numGender)(x)\n",
    "        x = Activation(finalAct, name=\"gender_output\")(x)\n",
    " \n",
    "        # return the color prediction sub-network\n",
    "        return x\n",
    "    \n",
    "    @staticmethod\n",
    "    def build(width, height, numAges, numGenders, finalAct=\"softmax\"):\n",
    "        # initialize the input shape and channel dimension (this code\n",
    "        # assumes you are using TensorFlow which utilizes channels\n",
    "        # last ordering)\n",
    "        inputShape = (height, width, 3)\n",
    "        chanDim = -1\n",
    " \n",
    "        # construct both the \"category\" and \"color\" sub-networks\n",
    "        inputs = Input(shape=inputShape)\n",
    "        agesBranch = FaceNet.build_ages_branch(inputs,\n",
    "            numAges, finalAct=finalAct, chanDim=chanDim)\n",
    "        \n",
    "        genderBranch = FaceNet.build_gender_branch(inputs,\n",
    "            numGenders, finalAct=finalAct, chanDim=chanDim)\n",
    " \n",
    "        # create the model using our input (the batch of images) and\n",
    "        # two separate outputs -- one for the clothing category\n",
    "        # branch and another for the color branch, respectively\n",
    "        model = Model(\n",
    "            inputs=inputs,\n",
    "            outputs=[agesBranch, genderBranch],\n",
    "            name=\"FaceNet\")\n",
    " \n",
    "        # return the constructed network architecture\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix seed for reproducible results (only works on CPU, not GPU)\n",
    "seed = 42\n",
    "np.random.seed(seed=seed)\n",
    "tf.set_random_seed(seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the number of epochs to train for, initial learning rate,\n",
    "# batch size, and image dimensions\n",
    "EPOCHS = 100\n",
    "INIT_LR = 1e-3\n",
    "BS = 32\n",
    "IMAGE_DIMS = (96, 96, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x: 3500 | valid_x: 1000\n"
     ]
    }
   ],
   "source": [
    "# Create inputs\n",
    "\n",
    "# train\n",
    "# loop over the input images\n",
    "train_x = []\n",
    "for imagePath in x_train_p:\n",
    "    # load the image, pre-process it, and store it in the data list\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = img_to_array(image)\n",
    "    train_x.append(image)\n",
    "    \n",
    "# valid\n",
    "# loop over the input images\n",
    "valid_x = []\n",
    "for imagePath in x_valid_p:\n",
    "    # load the image, pre-process it, and store it in the data list\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = img_to_array(image)\n",
    "    valid_x.append(image)\n",
    " \n",
    "print(\"train_x: {} | valid_x: {}\".format(len(train_x), len(valid_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to string\n",
    "y_train_age = y_train_age.astype(\"str\")\n",
    "y_valid_age = y_valid_age.astype(\"str\")\n",
    "y_test_age = y_test_age.astype(\"str\")\n",
    "\n",
    "y_train_gender = y_train_gender.astype(\"str\")\n",
    "y_valid_gender = y_valid_gender.astype(\"str\")\n",
    "y_test_gender = y_test_gender.astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['f', 'm', 'm', ..., 'f', 'f', 'm'], dtype='<U1')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n",
      "[INFO] train data matrix: 756.00MB\n",
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n",
      "[INFO] valid data matrix: 216.00MB\n",
      "[INFO] class labels:\n",
      "train_x: 3500\n",
      "y_train_age: 3500\n",
      "valid_x 1000\n",
      "y_valid_age 1000\n"
     ]
    }
   ],
   "source": [
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "train_x = np.array(train_x, dtype=\"float\") / 255.0\n",
    "\n",
    "lb_gender = LabelBinarizer()\n",
    "lb_age = LabelBinarizer()\n",
    "\n",
    "y_train_gender = lb_gender.fit_transform(y_train_gender)\n",
    "y_train_age = lb_age.fit_transform(y_train_age)\n",
    "print(y_train_gender)\n",
    "y_train_gender = np.array(y_train_gender)\n",
    "y_train_age = np.array(y_train_age)\n",
    "\n",
    "# print(train_y)\n",
    "print(\"[INFO] train data matrix: {:.2f}MB\".format(\n",
    "\ttrain_x.nbytes / (1024 * 1000.0)))\n",
    " \n",
    "print(y_train_gender)\n",
    "# binarize the labels\n",
    "\n",
    " \n",
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "valid_x = np.array(valid_x, dtype=\"float\") / 255.0\n",
    "y_valid_gender = np.array(y_valid_gender)\n",
    "y_valid_age = np.array(y_valid_age)\n",
    "print(\"[INFO] valid data matrix: {:.2f}MB\".format(\n",
    "\tvalid_x.nbytes / (1024 * 1000.0)))\n",
    " \n",
    "# binarize the labels\n",
    "print(\"[INFO] class labels:\")\n",
    "# mlb = MultiLabelBinarizer()\n",
    "y_valid_gender = lb_gender.transform(y_valid_gender)\n",
    "y_valid_age = lb_age.transform(y_valid_age)\n",
    "    \n",
    "print(\"train_x:\",len(train_x))\n",
    "print(\"y_train_age:\",len(y_train_age))\n",
    "print(\"valid_x\", len(valid_x))\n",
    "print(\"y_valid_age\",len(y_valid_age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_gender = [y_train_gender, 1 - y_train_gender]\n",
    "y_valid_gender = [y_valid_gender, 1 - y_valid_gender]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_gender = np.array(y_train_gender).squeeze().T\n",
    "y_valid_gender = np.array(y_valid_gender).squeeze().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
    "\theight_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "\thorizontal_flip=True, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ages number 78 | Gender number 2\n",
      "[INFO] compiling model...\n",
      "[INFO] training network...\n",
      "Train on 3500 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "3500/3500 [==============================] - 105s 30ms/step - loss: 5.7972 - ages_output_loss: 4.8332 - gender_output_loss: 0.9640 - ages_output_acc: 0.0349 - gender_output_acc: 0.5957 - val_loss: 6.0417 - val_ages_output_loss: 5.3430 - val_gender_output_loss: 0.6987 - val_ages_output_acc: 0.0430 - val_gender_output_acc: 0.6580\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mate/.virtualenvs/deeplearn_gpu/lib/python3.6/site-packages/keras/callbacks.py:434: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2720/3500 [======================>.......] - ETA: 21s - loss: 5.0137 - ages_output_loss: 4.2545 - gender_output_loss: 0.7593 - ages_output_acc: 0.0651 - gender_output_acc: 0.6357"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-b57b93b9f886>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m      )\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/deeplearn_gpu/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.virtualenvs/deeplearn_gpu/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/deeplearn_gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/deeplearn_gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/deeplearn_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# initialize the model\n",
    "print(\"Ages number\", len(lb_age.classes_), \"| Gender number\" ,len(lb_gender.classes_))\n",
    "print(\"[INFO] compiling model...\")\n",
    "# load model\n",
    "model = FaceNet.build(IMAGE_DIMS[0], IMAGE_DIMS[1], numGenders=len(lb_gender.classes_), numAges=len(lb_age.classes_), finalAct=\"softmax\")\n",
    "# create optimazitions method\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "\n",
    "#model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "#\tmetrics=[\"accuracy\"])\n",
    "losses = {\n",
    "\t\"ages_output\": \"categorical_crossentropy\",\n",
    "\t\"gender_output\": \"categorical_crossentropy\",\n",
    "}\n",
    "lossWeights = {\"ages_output\": 1.0, \"gender_output\": 1.0}\n",
    "\n",
    "model.compile(loss=losses, optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "\n",
    "# Create callback list for checkpoint and Earlystopping\n",
    "callbacks_list = [\n",
    "        ModelCheckpoint(project_path+\"multi_model.hdf5\", monitor='val_acc', verbose=1, save_best_only=True),\n",
    "        EarlyStopping(monitor='val_loss', patience=10, verbose=0)\n",
    "    ]\n",
    "\n",
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "\n",
    "History = model.fit(\n",
    "        train_x,\n",
    "        {\"ages_output\": y_train_age, \"gender_output\": y_train_gender},\n",
    "        validation_data=(valid_x,\n",
    "        {\"ages_output\": y_valid_age, \"gender_output\": y_valid_gender}),\n",
    "        epochs=EPOCHS,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks_list,\n",
    "     )\n",
    "\n",
    "\n",
    "# save the model to disk\n",
    "print(\"[INFO] serializing network...\")\n",
    "model.save(project_path+\"multi_model.hdf5\")\n",
    " \n",
    "# save the category binarizer to disk\n",
    "print(\"[INFO] serializing category label binarizer...\")\n",
    "f = open(project_path+\"ages.label\", \"wb\")\n",
    "f.write(pickle.dumps(lb_age))\n",
    "f.close()\n",
    " \n",
    "# save the color binarizer to disk\n",
    "print(\"[INFO] serializing color label binarizer...\")\n",
    "f = open(project_path+\"gender.label\", \"wb\")\n",
    "f.write(pickle.dumps(lb_gender))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REAL_EPOCH = len(model.history.epoch)\n",
    "print(y_train_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_names = [\"val_ages_output_acc\", \"val_gender_output_acc\"]\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "(fig, ax) = plt.subplots(2, 1, figsize=(8,8))\n",
    "\n",
    "for (i, l) in enumerate(accuracy_names):\n",
    "    ax[i].set_title(\"Accuracy for {}\".format(l))\n",
    "    ax[i].set_xlabel(\"Epochs\")\n",
    "    ax[i].set_ylabel(\"Accuracy\")\n",
    "    ax[i].plot(np.arange(0, REAL_EPOCH), History.history[l], label=l)\n",
    "    ax[i].plot(np.arange(0, REAL_EPOCH), History.history[l],label=l)\n",
    "    ax[i].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"multi.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load the image\n",
    "image = cv2.imread(project_path+\"me3.jpg\")\n",
    "# image = cv2.imread(\"/home/mate/Pictures/dorka1.jpg\")\n",
    "face_cascade = cv2.CascadeClassifier('detector/haarcascade_frontalface_default.xml')\n",
    "\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n",
    "\n",
    "bb = []\n",
    "i = 0\n",
    "output = image.copy()\n",
    "for (x,y,w,h) in faces:\n",
    "    bb.append([w * h, i])\n",
    "    cv2.rectangle(output,(x,y),(x+w,y+h),(255,0,0),2)\n",
    " #   roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = image[y:y+h, x:x+w]\n",
    "    i += 1\n",
    "    print(i)\n",
    "    break\n",
    "\n",
    "# pre-process the image for classification\n",
    "image = cv2.resize(image, (96, 96))\n",
    "image = image.astype(\"float\") / 255.0\n",
    "image = img_to_array(image)\n",
    "image = np.expand_dims(image, axis=0)\n",
    "\n",
    "# load the trained convolutional neural network and the label\n",
    "# binarizer\n",
    "print(\"[INFO] loading network...\")\n",
    "model = load_model(project_path+\"model.hdf5\")\n",
    "lb = pickle.loads(open(project_path+\"label.label\", \"rb\").read())\n",
    " \n",
    "# classify the input image\n",
    "print(\"[INFO] classifying image...\")\n",
    "proba = model.predict(image)[0]\n",
    "# idx = np.argmax(proba)\n",
    "idxs = np.argsort(proba)#[::-1][:2]\n",
    "# label = lb.classes_[idx]\n",
    "# loop over the indexes of the high confidence class labels\n",
    "for (i, j) in enumerate(idxs):\n",
    "\t# build the label and draw the label on the image\n",
    "\tlabel = \"{}: {:.2f}%\".format(mlb.classes_[j], proba[j] * 100)\n",
    "\tcv2.putText(output, label, (10, (i * 30) + 25), \n",
    "\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    " \n",
    "# show the probabilities for each of the individual labels\n",
    "for (label, p) in zip(mlb.classes_, proba):\n",
    "\tprint(\"{}: {:.2f}%\".format(label, p * 100))\n",
    "# \tcv2.putText(output, label, (10, (i * 30) + 25), \n",
    "# \t\tcv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    " \n",
    "# show the probabilities for each of the individual labels\n",
    "output = cv2.cvtColor(output, cv2.COLOR_BGR2RGB)\n",
    "# show the output image\n",
    "# print(\"[INFO] {} years old\".format(label))\n",
    "plt.imshow(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
